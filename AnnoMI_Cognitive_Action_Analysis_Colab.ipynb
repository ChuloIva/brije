{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnnoMI Cognitive Action Analysis - Comprehensive Meta-Analysis\n",
    "\n",
    "This notebook analyzes the AnnoMI therapeutic conversation dataset using universal cognitive action probe inference.\n",
    "\n",
    "**Features:**\n",
    "- \u2705 Universal probe inference across all layers (21-30)\n",
    "- \u2705 Cognitive action detection for all therapist/client utterances\n",
    "- \u2705 Client vs Therapist cognitive pattern analysis\n",
    "- \u2705 Topic-specific cognitive action distribution\n",
    "- \u2705 Temporal distribution analysis (10 conversation stages)\n",
    "- \u2705 Comprehensive visualizations\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab with GPU (T4 or better)\n",
    "- ~15 GB VRAM\n",
    "- Runtime: ~3-4 hours for full dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e3 Check GPU and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  WARNING: No GPU detected! This will be very slow on CPU.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\ufe0f\u20e3 Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone the repository\n",
    "repo_url = \"https://github.com/ChuloIva/brije.git\"\n",
    "repo_name = \"brije\"\n",
    "\n",
    "if not os.path.exists(repo_name):\n",
    "    print(\"\ud83d\udce5 Cloning Brije repository...\")\n",
    "    !git clone {repo_url}\n",
    "    print(\"\u2705 Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"\u2705 Repository already exists\")\n",
    "    print(\"\ud83d\udd04 Pulling latest changes...\")\n",
    "    !cd {repo_name} && git pull\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir(repo_name)\n",
    "print(f\"\\n\ud83d\udcc1 Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"\ud83d\udce6 Installing dependencies...\\n\")\n",
    "\n",
    "# Core dependencies\n",
    "print(\"Installing core packages...\")\n",
    "!pip install -q torch transformers h5py scikit-learn tqdm matplotlib seaborn pandas\n",
    "\n",
    "# Clone and install nnsight\n",
    "nnsight_dir = \"third_party/nnsight\"\n",
    "nnsight_repo = \"https://github.com/ndif-team/nnsight\"\n",
    "\n",
    "print(\"\\n\ud83d\udce6 Setting up nnsight...\")\n",
    "if not os.path.exists(nnsight_dir) or not os.listdir(nnsight_dir):\n",
    "    print(\"   Cloning nnsight repository...\")\n",
    "    os.makedirs(\"third_party\", exist_ok=True)\n",
    "    !git clone {nnsight_repo} {nnsight_dir}\n",
    "    print(\"   \u2705 nnsight repository cloned\")\n",
    "else:\n",
    "    print(\"   \u2705 nnsight repository already exists\")\n",
    "\n",
    "# Install nnsight\n",
    "print(\"   Installing nnsight...\")\n",
    "!pip install -q -e {nnsight_dir}\n",
    "\n",
    "print(\"\\n\u2705 All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3\ufe0f\u20e3 Verify Pre-trained Probes\n\nThe pre-trained probes are included in the repository. Let's verify they exist."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import glob\n\n# Check for probes in the repository\nlocal_probes_dir = 'data/probes_binary'\n\nprobe_dirs = glob.glob(f'{local_probes_dir}/layer_*')\n\nif probe_dirs:\n    print(\"\u2705 Found pre-trained probes in repository\")\n    print(f\"\\n\ud83d\udcca Available probe layers: {len(probe_dirs)}\")\n    \n    for probe_dir in sorted(probe_dirs)[:5]:\n        layer_num = os.path.basename(probe_dir).replace('layer_', '')\n        probe_files = glob.glob(f\"{probe_dir}/probe_*.pth\")\n        print(f\"   Layer {layer_num}: {len(probe_files)} probes\")\n    \n    if len(probe_dirs) > 5:\n        print(f\"   ... and {len(probe_dirs) - 5} more layers\")\nelse:\n    print(\"\u26a0\ufe0f  No probes found in:\", local_probes_dir)\n    print(\"\\n\ud83d\udca1 Please train probes first using:\")\n    print(\"   Brije_Full_Pipeline_Colab.ipynb\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\ufe0f\u20e3 Login to Hugging Face (for Gemma 3 4B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\ufe0f\u20e3 Load and Explore AnnoMI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load AnnoMI-simple.csv\n",
    "annomi_path = 'third_party/AnnoMI/AnnoMI-simple.csv'\n",
    "\n",
    "print(\"\ud83d\udcca Loading AnnoMI dataset...\")\n",
    "df = pd.read_csv(annomi_path)\n",
    "\n",
    "print(f\"\\n\u2705 Loaded {len(df)} utterances\")\n",
    "print(f\"   Transcripts: {df['transcript_id'].nunique()}\")\n",
    "print(f\"   Topics: {df['topic'].nunique()}\")\n",
    "print(f\"   Therapist utterances: {len(df[df['interlocutor'] == 'therapist'])}\")\n",
    "print(f\"   Client utterances: {len(df[df['interlocutor'] == 'client'])}\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE UTTERANCES\")\n",
    "print(\"=\"*80)\n",
    "print(df[['interlocutor', 'utterance_text', 'topic']].head(10).to_string(index=False))\n",
    "\n",
    "# Show topic distribution\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOPIC DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "topic_counts = df.groupby('topic')['transcript_id'].nunique().sort_values(ascending=False)\n",
    "for topic, count in topic_counts.items():\n",
    "    print(f\"  {topic:40s}: {count:3d} transcripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\ufe0f\u20e3 Initialize Universal Probe Inference Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src', 'probes'))\n",
    "\n",
    "from universal_multi_layer_inference import UniversalMultiLayerInferenceEngine\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize the engine\n",
    "print(\"\ud83d\ude80 Initializing Universal Probe Inference Engine...\\n\")\n",
    "\n",
    "engine = UniversalMultiLayerInferenceEngine(\n",
    "    probes_base_dir=Path('data/probes_binary'),\n",
    "    model_name='google/gemma-3-4b-it',\n",
    "    layer_range=(21, 30)  # Layers 21-30 (adjust based on your trained probes)\n",
    ")\n",
    "\n",
    "print(\"\\n\u2705 Engine initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7\ufe0f\u20e3 Run Cognitive Action Inference on All Utterances\n",
    "\n",
    "This will analyze all utterances in the dataset and detect cognitive actions.\n",
    "\n",
    "**\u23f0 Expected time:** ~2-4 hours for full dataset (~3,000 utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"\ud83e\udde0 Running cognitive action inference on all utterances...\")\n",
    "print(f\"   Total utterances: {len(df)}\")\n",
    "print(f\"   This may take 2-4 hours...\\n\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('output/annomi_analysis')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Store predictions\n",
    "predictions_list = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Process each utterance\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing utterances\"):\n",
    "    utterance_text = row['utterance_text']\n",
    "    \n",
    "    try:\n",
    "        # Run universal inference (grouped by action)\n",
    "        action_preds = engine.predict_by_action(\n",
    "            utterance_text,\n",
    "            threshold=0.1,\n",
    "            aggregation=\"max\"\n",
    "        )\n",
    "        \n",
    "        # Get all layers where each action was detected\n",
    "        all_layer_preds = engine.predict_all(\n",
    "            utterance_text,\n",
    "            threshold=0.1\n",
    "        )\n",
    "        \n",
    "        # Group predictions by action with layer info\n",
    "        action_layer_map = defaultdict(list)\n",
    "        for pred in all_layer_preds:\n",
    "            if pred.is_active:\n",
    "                action_layer_map[pred.action_name].append({\n",
    "                    'layer': pred.layer,\n",
    "                    'confidence': pred.confidence\n",
    "                })\n",
    "        \n",
    "        # Store prediction with metadata\n",
    "        predictions_list.append({\n",
    "            'utterance_id': row['utterance_id'],\n",
    "            'transcript_id': row['transcript_id'],\n",
    "            'interlocutor': row['interlocutor'],\n",
    "            'topic': row['topic'],\n",
    "            'utterance_text': utterance_text,\n",
    "            'mi_quality': row['mi_quality'],\n",
    "            'main_therapist_behaviour': row.get('main_therapist_behaviour', None),\n",
    "            'client_talk_type': row.get('client_talk_type', None),\n",
    "            'predictions': action_preds,\n",
    "            'action_layer_details': dict(action_layer_map)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n\u26a0\ufe0f  Error processing utterance {idx}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Save checkpoint every 100 utterances\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        checkpoint_file = output_dir / f'predictions_checkpoint_{idx+1}.json'\n",
    "        import json\n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            json.dump(predictions_list, f, indent=2, default=str)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        avg_time = elapsed / (idx + 1)\n",
    "        remaining = avg_time * (len(df) - (idx + 1))\n",
    "        print(f\"\\n\u2713 Checkpoint saved. ETA: {remaining/3600:.1f} hours\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n\u2705 Inference complete!\")\n",
    "print(f\"   Time elapsed: {elapsed_time/3600:.2f} hours\")\n",
    "print(f\"   Average time per utterance: {elapsed_time/len(df):.2f} seconds\")\n",
    "\n",
    "# Save final predictions\n",
    "import json\n",
    "predictions_file = output_dir / 'all_predictions.json'\n",
    "with open(predictions_file, 'w') as f:\n",
    "    json.dump(predictions_list, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n\ud83d\udcbe Predictions saved to: {predictions_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-filter-header",
   "metadata": {},
   "source": [
    "## 7\ufe0f\u20e3.1 Filter High-Confidence Cognitive Actions\n\n",
    "Filter predictions to keep only cognitive actions that:\n",
    "- Appear on **more than 2 layers**, OR\n",
    "- Have **100% confidence score**\n\n",
    "This removes noise and focuses on robust cognitive action detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-filter-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83d\udd0d Filtering cognitive actions for high confidence...\")\n",
    "print(f\"   Total predictions before filtering: {len(predictions_list)}\")\n",
    "\n",
    "# Save original predictions for comparison\n",
    "all_predictions = predictions_list.copy()\n",
    "\n",
    "# Filter each prediction to keep only high-confidence actions\n",
    "filtered_predictions_list = []\n",
    "\n",
    "for pred_data in predictions_list:\n",
    "    action_layer_details = pred_data.get('action_layer_details', {})\n",
    "    predictions = pred_data['predictions']\n",
    "    \n",
    "    # Create filtered predictions dict\n",
    "    filtered_predictions = {}\n",
    "    \n",
    "    for action_name, action_info in predictions.items():\n",
    "        if not action_info.get('is_active', False):\n",
    "            continue\n",
    "        \n",
    "        # Check filtering criteria\n",
    "        num_layers = len(action_layer_details.get(action_name, []))\n",
    "        max_confidence = max([layer_info['confidence'] for layer_info in action_layer_details.get(action_name, [])], default=0)\n",
    "        \n",
    "        # Keep if: appears on >2 layers OR has 100% confidence\n",
    "        if num_layers > 2 or max_confidence >= 1.0:\n",
    "            filtered_predictions[action_name] = action_info\n",
    "    \n",
    "    # Create filtered prediction entry\n",
    "    filtered_pred_data = pred_data.copy()\n",
    "    filtered_pred_data['predictions'] = filtered_predictions\n",
    "    filtered_predictions_list.append(filtered_pred_data)\n",
    "\n",
    "# Count statistics\n",
    "total_actions_before = sum(len([a for a, d in pred['predictions'].items() if d.get('is_active', False)]) \n",
    "                          for pred in all_predictions)\n",
    "total_actions_after = sum(len([a for a, d in pred['predictions'].items() if d.get('is_active', False)]) \n",
    "                         for pred in filtered_predictions_list)\n",
    "\n",
    "print(f\"   Total predictions after filtering: {len(filtered_predictions_list)}\")\n",
    "print(f\"   Active actions before: {total_actions_before}\")\n",
    "print(f\"   Active actions after: {total_actions_after}\")\n",
    "print(f\"   Removed: {total_actions_before - total_actions_after} actions ({(total_actions_before - total_actions_after)/total_actions_before*100:.1f}%)\")\n",
    "\n",
    "# Replace predictions_list with filtered version\n",
    "predictions_list = filtered_predictions_list\n",
    "\n",
    "# Save filtered predictions\n",
    "filtered_predictions_file = output_dir / 'all_predictions_filtered.json'\n",
    "with open(filtered_predictions_file, 'w') as f:\n",
    "    json.dump(predictions_list, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\n\u2705 Filtered predictions saved to: {filtered_predictions_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8\ufe0f\u20e3 Meta-Analysis 1: Client vs Therapist Cognitive Patterns"
   ],
   "id": "cell-18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"META-ANALYSIS 1: CLIENT VS THERAPIST COGNITIVE PATTERNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Aggregate cognitive actions by interlocutor\n",
    "therapist_actions = Counter()\n",
    "client_actions = Counter()\n",
    "\n",
    "for pred_data in predictions_list:\n",
    "    interlocutor = pred_data['interlocutor']\n",
    "    predictions = pred_data['predictions']\n",
    "    \n",
    "    for action_name, data in predictions.items():\n",
    "        if data.get('is_active', False):\n",
    "            # Weight by aggregate confidence\n",
    "            confidence = data['aggregate']\n",
    "            \n",
    "            if interlocutor == 'therapist':\n",
    "                therapist_actions[action_name] += confidence\n",
    "            else:\n",
    "                client_actions[action_name] += confidence\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 20 COGNITIVE ACTIONS: THERAPIST\")\n",
    "print(\"=\"*80)\n",
    "for action, score in therapist_actions.most_common(20):\n",
    "    bar = \"\u2588\" * int(score / 10)\n",
    "    print(f\"{action:35s} {score:7.2f} {bar}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 20 COGNITIVE ACTIONS: CLIENT\")\n",
    "print(\"=\"*80)\n",
    "for action, score in client_actions.most_common(20):\n",
    "    bar = \"\u2588\" * int(score / 10)\n",
    "    print(f\"{action:35s} {score:7.2f} {bar}\")\n",
    "\n",
    "# Find unique patterns\n",
    "therapist_only = set(therapist_actions.keys()) - set(client_actions.keys())\n",
    "client_only = set(client_actions.keys()) - set(therapist_actions.keys())\n",
    "\n",
    "if therapist_only:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COGNITIVE ACTIONS UNIQUE TO THERAPIST\")\n",
    "    print(\"=\"*80)\n",
    "    for action in sorted(therapist_only):\n",
    "        print(f\"  \u2022 {action}\")\n",
    "\n",
    "if client_only:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COGNITIVE ACTIONS UNIQUE TO CLIENT\")\n",
    "    print(\"=\"*80)\n",
    "    for action in sorted(client_only):\n",
    "        print(f\"  \u2022 {action}\")\n",
    "\n",
    "# Save analysis\n",
    "analysis_1 = {\n",
    "    'therapist_top_20': dict(therapist_actions.most_common(20)),\n",
    "    'client_top_20': dict(client_actions.most_common(20)),\n",
    "    'therapist_unique': list(therapist_only),\n",
    "    'client_unique': list(client_only)\n",
    "}\n",
    "\n",
    "with open(output_dir / 'analysis_1_client_vs_therapist.json', 'w') as f:\n",
    "    json.dump(analysis_1, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Analysis saved to: output/annomi_analysis/analysis_1_client_vs_therapist.json\")"
   ],
   "id": "cell-19"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9\ufe0f\u20e3 Meta-Analysis 2: Topic-Specific Cognitive Action Distribution"
   ],
   "id": "cell-20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"META-ANALYSIS 2: TOPIC-SPECIFIC COGNITIVE ACTION DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Aggregate by topic and interlocutor\n",
    "topic_actions = defaultdict(lambda: {'therapist': Counter(), 'client': Counter()})\n",
    "\n",
    "for pred_data in predictions_list:\n",
    "    topic = pred_data['topic']\n",
    "    interlocutor = pred_data['interlocutor']\n",
    "    predictions = pred_data['predictions']\n",
    "    \n",
    "    for action_name, data in predictions.items():\n",
    "        if data.get('is_active', False):\n",
    "            confidence = data['aggregate']\n",
    "            topic_actions[topic][interlocutor][action_name] += confidence\n",
    "\n",
    "# Analyze each topic\n",
    "for topic in sorted(topic_actions.keys()):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TOPIC: {topic.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    therapist = topic_actions[topic]['therapist']\n",
    "    client = topic_actions[topic]['client']\n",
    "    \n",
    "    print(f\"\\n  Top 10 Therapist Actions:\")\n",
    "    for action, score in therapist.most_common(10):\n",
    "        print(f\"    \u2022 {action:35s} {score:7.2f}\")\n",
    "    \n",
    "    print(f\"\\n  Top 10 Client Actions:\")\n",
    "    for action, score in client.most_common(10):\n",
    "        print(f\"    \u2022 {action:35s} {score:7.2f}\")\n",
    "\n",
    "# Save analysis\n",
    "analysis_2 = {}\n",
    "for topic, data in topic_actions.items():\n",
    "    analysis_2[topic] = {\n",
    "        'therapist_top_10': dict(data['therapist'].most_common(10)),\n",
    "        'client_top_10': dict(data['client'].most_common(10))\n",
    "    }\n",
    "\n",
    "with open(output_dir / 'analysis_2_topic_specific.json', 'w') as f:\n",
    "    json.dump(analysis_2, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Analysis saved to: output/annomi_analysis/analysis_2_topic_specific.json\")"
   ],
   "id": "cell-21"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd1f Meta-Analysis 3: Temporal Distribution (10 Conversation Stages)"
   ],
   "id": "cell-22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"META-ANALYSIS 3: TEMPORAL DISTRIBUTION (10 CONVERSATION STAGES)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Group predictions by transcript and split into 10 stages\n",
    "transcript_stages = defaultdict(lambda: {i: {'therapist': Counter(), 'client': Counter()} for i in range(10)})\n",
    "\n",
    "# Group by transcript\n",
    "transcript_groups = defaultdict(list)\n",
    "for pred_data in predictions_list:\n",
    "    transcript_id = pred_data['transcript_id']\n",
    "    transcript_groups[transcript_id].append(pred_data)\n",
    "\n",
    "# Process each transcript\n",
    "for transcript_id, utterances in transcript_groups.items():\n",
    "    # Sort by utterance_id\n",
    "    utterances = sorted(utterances, key=lambda x: x['utterance_id'])\n",
    "    \n",
    "    # Divide into 10 stages\n",
    "    n = len(utterances)\n",
    "    stage_size = n / 10\n",
    "    \n",
    "    for i, utterance in enumerate(utterances):\n",
    "        stage = min(int(i / stage_size), 9)  # 0-9\n",
    "        interlocutor = utterance['interlocutor']\n",
    "        \n",
    "        for action_name, data in utterance['predictions'].items():\n",
    "            if data.get('is_active', False):\n",
    "                confidence = data['aggregate']\n",
    "                transcript_stages[transcript_id][stage][interlocutor][action_name] += confidence\n",
    "\n",
    "# Aggregate across all transcripts\n",
    "stage_aggregates = {i: {'therapist': Counter(), 'client': Counter()} for i in range(10)}\n",
    "\n",
    "for transcript_data in transcript_stages.values():\n",
    "    for stage, data in transcript_data.items():\n",
    "        for interlocutor in ['therapist', 'client']:\n",
    "            stage_aggregates[stage][interlocutor].update(data[interlocutor])\n",
    "\n",
    "# Display results\n",
    "for stage in range(10):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STAGE {stage + 1}/10 ({stage*10}%-{(stage+1)*10}% through conversation)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\n  Top 5 Therapist Actions:\")\n",
    "    for action, score in stage_aggregates[stage]['therapist'].most_common(5):\n",
    "        print(f\"    \u2022 {action:35s} {score:7.2f}\")\n",
    "    \n",
    "    print(f\"\\n  Top 5 Client Actions:\")\n",
    "    for action, score in stage_aggregates[stage]['client'].most_common(5):\n",
    "        print(f\"    \u2022 {action:35s} {score:7.2f}\")\n",
    "\n",
    "# Save analysis\n",
    "analysis_3 = {}\n",
    "for stage, data in stage_aggregates.items():\n",
    "    analysis_3[f'stage_{stage+1}'] = {\n",
    "        'stage_range': f\"{stage*10}%-{(stage+1)*10}%\",\n",
    "        'therapist_top_10': dict(data['therapist'].most_common(10)),\n",
    "        'client_top_10': dict(data['client'].most_common(10))\n",
    "    }\n",
    "\n",
    "with open(output_dir / 'analysis_3_temporal_distribution.json', 'w') as f:\n",
    "    json.dump(analysis_3, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Analysis saved to: output/annomi_analysis/analysis_3_temporal_distribution.json\")"
   ],
   "id": "cell-23"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e31\ufe0f\u20e3 Visualizations: Client vs Therapist Patterns"
   ],
   "id": "cell-24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "# Get top actions\n",
    "top_therapist = dict(therapist_actions.most_common(15))\n",
    "top_client = dict(client_actions.most_common(15))\n",
    "\n",
    "# Combine and get unique actions\n",
    "all_actions = set(list(top_therapist.keys()) + list(top_client.keys()))\n",
    "actions = sorted(all_actions, key=lambda x: max(top_therapist.get(x, 0), top_client.get(x, 0)), reverse=True)\n",
    "\n",
    "therapist_scores = [top_therapist.get(a, 0) for a in actions]\n",
    "client_scores = [top_client.get(a, 0) for a in actions]\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Plot 1: Comparison bar chart\n",
    "x = np.arange(len(actions))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].barh(x - width/2, therapist_scores, width, label='Therapist', color='steelblue', alpha=0.8)\n",
    "axes[0].barh(x + width/2, client_scores, width, label='Client', color='coral', alpha=0.8)\n",
    "axes[0].set_yticks(x)\n",
    "axes[0].set_yticklabels(actions, fontsize=10)\n",
    "axes[0].set_xlabel('Aggregate Confidence Score', fontsize=12)\n",
    "axes[0].set_title('Cognitive Action Comparison:\\nTherapist vs Client', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Plot 2: Ratio comparison (Therapist / Client)\n",
    "ratios = []\n",
    "ratio_actions = []\n",
    "for action in actions:\n",
    "    t_score = top_therapist.get(action, 0.1)\n",
    "    c_score = top_client.get(action, 0.1)\n",
    "    ratio = np.log2(t_score / c_score) if c_score > 0 else 0\n",
    "    ratios.append(ratio)\n",
    "    ratio_actions.append(action)\n",
    "\n",
    "colors = ['steelblue' if r > 0 else 'coral' for r in ratios]\n",
    "axes[1].barh(range(len(ratio_actions)), ratios, color=colors, alpha=0.8)\n",
    "axes[1].set_yticks(range(len(ratio_actions)))\n",
    "axes[1].set_yticklabels(ratio_actions, fontsize=10)\n",
    "axes[1].set_xlabel('Log2(Therapist/Client)', fontsize=12)\n",
    "axes[1].set_title('Cognitive Action Bias:\\nTherapist-Dominant (blue) vs Client-Dominant (red)', fontsize=14, fontweight='bold')\n",
    "axes[1].axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'viz_1_client_vs_therapist.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2705 Visualization saved to: output/annomi_analysis/viz_1_client_vs_therapist.png\")"
   ],
   "id": "cell-25"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e32\ufe0f\u20e3 Visualizations: Temporal Distribution Heatmap"
   ],
   "id": "cell-26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap data for temporal distribution\n",
    "# Get top actions overall\n",
    "all_actions_combined = therapist_actions + client_actions\n",
    "top_actions_for_heatmap = [action for action, _ in all_actions_combined.most_common(20)]\n",
    "\n",
    "# Build matrices for therapist and client\n",
    "therapist_heatmap = np.zeros((len(top_actions_for_heatmap), 10))\n",
    "client_heatmap = np.zeros((len(top_actions_for_heatmap), 10))\n",
    "\n",
    "for i, action in enumerate(top_actions_for_heatmap):\n",
    "    for stage in range(10):\n",
    "        therapist_heatmap[i, stage] = stage_aggregates[stage]['therapist'].get(action, 0)\n",
    "        client_heatmap[i, stage] = stage_aggregates[stage]['client'].get(action, 0)\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 18))\n",
    "\n",
    "# Therapist heatmap\n",
    "im1 = axes[0].imshow(therapist_heatmap, aspect='auto', cmap='Blues', interpolation='nearest')\n",
    "axes[0].set_xticks(range(10))\n",
    "axes[0].set_xticklabels([f'Stage {i+1}\\n({i*10}-{(i+1)*10}%)' for i in range(10)], fontsize=10)\n",
    "axes[0].set_yticks(range(len(top_actions_for_heatmap)))\n",
    "axes[0].set_yticklabels(top_actions_for_heatmap, fontsize=10)\n",
    "axes[0].set_title('Therapist Cognitive Actions Across Conversation Stages', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im1, ax=axes[0], label='Aggregate Confidence Score')\n",
    "\n",
    "# Client heatmap\n",
    "im2 = axes[1].imshow(client_heatmap, aspect='auto', cmap='Oranges', interpolation='nearest')\n",
    "axes[1].set_xticks(range(10))\n",
    "axes[1].set_xticklabels([f'Stage {i+1}\\n({i*10}-{(i+1)*10}%)' for i in range(10)], fontsize=10)\n",
    "axes[1].set_yticks(range(len(top_actions_for_heatmap)))\n",
    "axes[1].set_yticklabels(top_actions_for_heatmap, fontsize=10)\n",
    "axes[1].set_title('Client Cognitive Actions Across Conversation Stages', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im2, ax=axes[1], label='Aggregate Confidence Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'viz_2_temporal_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2705 Visualization saved to: output/annomi_analysis/viz_2_temporal_heatmap.png\")"
   ],
   "id": "cell-27"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e33\ufe0f\u20e3 Visualizations: Topic-Specific Cognitive Patterns"
   ],
   "id": "cell-28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stacked bar chart showing top actions per topic\n",
    "topics_to_plot = list(topic_actions.keys())[:6]  # Plot top 6 topics\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, topic in enumerate(topics_to_plot):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Get top 10 actions for this topic (combined)\n",
    "    combined = topic_actions[topic]['therapist'] + topic_actions[topic]['client']\n",
    "    top_10 = [action for action, _ in combined.most_common(10)]\n",
    "    \n",
    "    therapist_vals = [topic_actions[topic]['therapist'].get(a, 0) for a in top_10]\n",
    "    client_vals = [topic_actions[topic]['client'].get(a, 0) for a in top_10]\n",
    "    \n",
    "    x = np.arange(len(top_10))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, therapist_vals, width, label='Therapist', color='steelblue', alpha=0.8)\n",
    "    ax.bar(x + width/2, client_vals, width, label='Client', color='coral', alpha=0.8)\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(top_10, rotation=45, ha='right', fontsize=8)\n",
    "    ax.set_ylabel('Confidence Score', fontsize=10)\n",
    "    ax.set_title(f'{topic}', fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'viz_3_topic_specific.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2705 Visualization saved to: output/annomi_analysis/viz_3_topic_specific.png\")"
   ],
   "id": "cell-29"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e34\ufe0f\u20e3 Summary Report"
   ],
   "id": "cell-30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Dataset Statistics:\")\n",
    "print(f\"   Total utterances analyzed: {len(predictions_list)}\")\n",
    "print(f\"   Transcripts: {df['transcript_id'].nunique()}\")\n",
    "print(f\"   Topics: {df['topic'].nunique()}\")\n",
    "print(f\"   Therapist utterances: {len([p for p in predictions_list if p['interlocutor'] == 'therapist'])}\")\n",
    "print(f\"   Client utterances: {len([p for p in predictions_list if p['interlocutor'] == 'client'])}\")\n",
    "\n",
    "print(f\"\\n\ud83e\udde0 Key Findings:\")\n",
    "\n",
    "print(f\"\\n1\ufe0f\u20e3 Most Common Therapist Cognitive Actions:\")\n",
    "for i, (action, score) in enumerate(therapist_actions.most_common(5), 1):\n",
    "    print(f\"   {i}. {action:35s} (score: {score:.2f})\")\n",
    "\n",
    "print(f\"\\n2\ufe0f\u20e3 Most Common Client Cognitive Actions:\")\n",
    "for i, (action, score) in enumerate(client_actions.most_common(5), 1):\n",
    "    print(f\"   {i}. {action:35s} (score: {score:.2f})\")\n",
    "\n",
    "print(f\"\\n3\ufe0f\u20e3 Temporal Patterns:\")\n",
    "print(f\"   Early stage (0-30%) dominant actions:\")\n",
    "early_combined = stage_aggregates[0]['therapist'] + stage_aggregates[0]['client'] + \\\n",
    "                 stage_aggregates[1]['therapist'] + stage_aggregates[1]['client'] + \\\n",
    "                 stage_aggregates[2]['therapist'] + stage_aggregates[2]['client']\n",
    "for action, score in early_combined.most_common(3):\n",
    "    print(f\"      \u2022 {action}\")\n",
    "\n",
    "print(f\"\\n   Late stage (70-100%) dominant actions:\")\n",
    "late_combined = stage_aggregates[7]['therapist'] + stage_aggregates[7]['client'] + \\\n",
    "                stage_aggregates[8]['therapist'] + stage_aggregates[8]['client'] + \\\n",
    "                stage_aggregates[9]['therapist'] + stage_aggregates[9]['client']\n",
    "for action, score in late_combined.most_common(3):\n",
    "    print(f\"      \u2022 {action}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc1 Output Files:\")\n",
    "print(f\"   \u2022 all_predictions.json - Full prediction data\")\n",
    "print(f\"   \u2022 analysis_1_client_vs_therapist.json - Client vs Therapist analysis\")\n",
    "print(f\"   \u2022 analysis_2_topic_specific.json - Topic-specific analysis\")\n",
    "print(f\"   \u2022 analysis_3_temporal_distribution.json - Temporal analysis\")\n",
    "print(f\"   \u2022 viz_1_client_vs_therapist.png - Client vs Therapist visualization\")\n",
    "print(f\"   \u2022 viz_2_temporal_heatmap.png - Temporal heatmap\")\n",
    "print(f\"   \u2022 viz_3_topic_specific.png - Topic-specific visualization\")\n",
    "\n",
    "print(f\"\\n\u2705 All analyses complete!\")\n",
    "print(f\"\\n\ud83d\udcc2 All outputs saved to: {output_dir}\")\n",
    "print(\"=\"*80)"
   ],
   "id": "cell-31"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e35\ufe0f\u20e3 Backup to Google Drive"
   ],
   "id": "cell-32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup all outputs to Google Drive\n",
    "drive_output_dir = '/content/drive/MyDrive/brije_outputs/annomi_analysis'\n",
    "\n",
    "print(\"\ud83d\udce5 Backing up results to Google Drive...\")\n",
    "!mkdir -p {drive_output_dir}\n",
    "!cp -r {output_dir}/* {drive_output_dir}/\n",
    "\n",
    "print(f\"\u2705 Backup complete! Results saved to: {drive_output_dir}\")"
   ],
   "id": "cell-33"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}