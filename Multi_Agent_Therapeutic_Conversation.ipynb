{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Therapeutic Conversation with Cognitive Action Probes\n",
    "\n",
    "This notebook explores therapeutic conversations between two AI agents (therapist and client) using cognitive action probes to analyze their thinking patterns.\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Therapist-Client conversation simulation\n",
    "- ‚úÖ Real-time cognitive action detection using probes\n",
    "- ‚úÖ Multiple conversation scenarios to test\n",
    "- ‚úÖ 6-10 turn conversations\n",
    "- ‚úÖ Detailed probe analysis for both agents\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab with GPU (T4 or better)\n",
    "- ~10 GB VRAM\n",
    "- Runtime: ~15-20 minutes total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check GPU and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: No GPU detected! This will be very slow on CPU.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone the repository\n",
    "repo_url = \"https://github.com/ChuloIva/brije.git\"\n",
    "repo_name = \"brije\"\n",
    "\n",
    "if not os.path.exists(repo_name):\n",
    "    print(\"üì• Cloning Brije repository...\")\n",
    "    !git clone {repo_url}\n",
    "    print(\"‚úÖ Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists\")\n",
    "    print(\"üîÑ Pulling latest changes...\")\n",
    "    !cd {repo_name} && git pull\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir(repo_name)\n",
    "print(f\"\\nüìÅ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"üì¶ Installing dependencies...\\n\")\n",
    "\n",
    "# Core dependencies for the notebook\n",
    "print(\"Installing core packages...\")\n",
    "!pip install -q torch transformers h5py scikit-learn tqdm matplotlib seaborn\n",
    "\n",
    "# Dependencies for liminal_backrooms\n",
    "print(\"\\nInstalling liminal_backrooms dependencies...\")\n",
    "!pip install -q python-dotenv requests Pillow\n",
    "\n",
    "# Optional API clients (only needed if you want to use other models later)\n",
    "# These won't be used for Gemma with probes, but prevents import errors\n",
    "print(\"\\nInstalling optional API clients (prevents import errors)...\")\n",
    "!pip install -q anthropic openai replicate together\n",
    "\n",
    "# Clone and install nnsight\n",
    "nnsight_dir = \"third_party/nnsight\"\n",
    "nnsight_repo = \"https://github.com/ndif-team/nnsight\"\n",
    "\n",
    "print(\"\\nüì¶ Setting up nnsight...\")\n",
    "if not os.path.exists(nnsight_dir) or not os.listdir(nnsight_dir):\n",
    "    print(\"   Cloning nnsight repository...\")\n",
    "    os.makedirs(\"third_party\", exist_ok=True)\n",
    "    !git clone {nnsight_repo} {nnsight_dir}\n",
    "    print(\"   ‚úÖ nnsight repository cloned\")\n",
    "else:\n",
    "    print(\"   ‚úÖ nnsight repository already exists\")\n",
    "\n",
    "# Install nnsight\n",
    "print(\"   Installing nnsight...\")\n",
    "!pip install -q -e {nnsight_dir}\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")\n",
    "print(\"\\nüìã Installed packages:\")\n",
    "print(\"   ‚Ä¢ PyTorch + Transformers (for Gemma 3 4B)\")\n",
    "print(\"   ‚Ä¢ nnsight (for activation extraction)\")\n",
    "print(\"   ‚Ä¢ scikit-learn (for probe models)\")\n",
    "print(\"   ‚Ä¢ python-dotenv, requests, Pillow (liminal_backrooms)\")\n",
    "print(\"   ‚Ä¢ matplotlib, seaborn (visualization)\")\n",
    "print(\"   ‚Ä¢ anthropic, openai, replicate, together (optional - prevents import errors)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Setup Environment (No API Keys Required!)\n",
    "\n",
    "**Note:** When using Gemma 3 4B with probes, the model runs **locally** on your GPU. No API keys or internet required!\n",
    "\n",
    "This cell creates a minimal .env file to prevent import errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a minimal .env file (not needed for Gemma, but prevents import errors)\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(\"# Gemma 3 4B runs locally - no API keys needed\\n\")\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")\n",
    "print(\"\\nüí° Important: Gemma 3 4B with probes runs entirely on your GPU.\")\n",
    "print(\"   ‚Ä¢ No API calls\")\n",
    "print(\"   ‚Ä¢ No API keys\") \n",
    "print(\"   ‚Ä¢ No internet required\")\n",
    "print(\"   ‚Ä¢ 100% local inference with real-time probe analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Download Pre-trained Probes (Optional but Recommended)\n",
    "\n",
    "If you have pre-trained probes, upload them to `data/probes_binary/`. Otherwise, the system will run without probe visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found pre-trained probes:\n",
      "   Layer 21: 45 probes\n",
      "   Layer 22: 45 probes\n",
      "   Layer 23: 45 probes\n",
      "   Layer 24: 45 probes\n",
      "   Layer 25: 45 probes\n",
      "   ... and 5 more layers\n",
      "\n",
      "üéØ Probes will be used for cognitive action detection!\n"
     ]
    }
   ],
   "source": [
    "# Check if probes exist\n",
    "import glob\n",
    "import os\n",
    "probe_dirs = glob.glob('data/probes_binary/layer_*')\n",
    "\n",
    "if probe_dirs:\n",
    "    print(\"‚úÖ Found pre-trained probes:\")\n",
    "    for probe_dir in sorted(probe_dirs)[:5]:\n",
    "        layer_num = os.path.basename(probe_dir).replace('layer_', '')\n",
    "        probe_files = glob.glob(f\"{probe_dir}/probe_*.pth\")\n",
    "        print(f\"   Layer {layer_num}: {len(probe_files)} probes\")\n",
    "    if len(probe_dirs) > 5:\n",
    "        print(f\"   ... and {len(probe_dirs) - 5} more layers\")\n",
    "    print(\"\\nüéØ Probes will be used for cognitive action detection!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No pre-trained probes found in data/probes_binary/\")\n",
    "    print(\"\\nüí° Options:\")\n",
    "    print(\"   1. Upload pre-trained probes to data/probes_binary/layer_XX/\")\n",
    "    print(\"   2. Train probes using Brije_Full_Pipeline_Colab.ipynb\")\n",
    "    print(\"   3. Continue without probes (conversations will still work)\")\n",
    "    print(\"\\n‚ö†Ô∏è  Continuing without probe visualization...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Add Therapeutic Conversation System Prompts\n",
    "\n",
    "We'll add a new system prompt pair for therapist-client conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Added therapeutic conversation system prompts!\n",
      "\n",
      "Available conversation types:\n",
      "   1. Backrooms\n",
      "   2. ASCII Art\n",
      "   3. Image Model Collaboration\n",
      "   4. Cognitive Roles - Analyst vs Creative\n",
      "   5. Cognitive Roles - Skeptic vs Optimist\n",
      "   6. Cognitive Roles - Metacognitive Explorer\n",
      "   7. Therapeutic Session - Therapist and Client\n"
     ]
    }
   ],
   "source": [
    "# Add therapeutic conversation prompts to config\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add liminal_backrooms to path\n",
    "sys.path.insert(0, str(Path.cwd() / \"third_party\" / \"liminal_backrooms\"))\n",
    "\n",
    "from third_party.liminal_backrooms.config import SYSTEM_PROMPT_PAIRS\n",
    "\n",
    "# Add therapeutic conversation prompt\n",
    "SYSTEM_PROMPT_PAIRS[\"Therapeutic Session - Therapist and Client\"] = {\n",
    "    \"AI_1\": \"\"\"You are a skilled therapist conducting a therapy session. Your role is to:\n",
    "- Listen actively and empathetically to the client\n",
    "- Ask thoughtful, open-ended questions to help the client explore their feelings\n",
    "- Notice patterns in the client's thinking and behavior\n",
    "- Help the client reframe negative thoughts and consider new perspectives\n",
    "- Validate emotions while gently challenging unhelpful beliefs\n",
    "- Guide the client toward insights and actionable strategies\n",
    "- Use techniques like cognitive reframing, perspective-taking, and emotional awareness\n",
    "\n",
    "Be warm, professional, and focused on helping the client gain clarity and develop coping strategies.\"\"\",\n",
    "    \n",
    "    \"AI_2\": \"\"\"You are a client in a therapy session. You are seeking help with various challenges such as:\n",
    "- Anxiety, stress, or overwhelming emotions\n",
    "- Relationship difficulties\n",
    "- Work-related stress or burnout\n",
    "- Self-doubt or negative self-talk\n",
    "- Difficulty making decisions\n",
    "- Processing difficult experiences\n",
    "\n",
    "Express your thoughts and feelings authentically. Sometimes you're uncertain, sometimes you have insights, sometimes you're confused. Be open to exploring your thinking patterns and considering new perspectives the therapist offers.\"\"\"\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Added therapeutic conversation system prompts!\")\n",
    "print(\"\\nAvailable conversation types:\")\n",
    "for i, prompt_name in enumerate(SYSTEM_PROMPT_PAIRS.keys(), 1):\n",
    "    print(f\"   {i}. {prompt_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Define Test Scenarios\n",
    "\n",
    "Different opening statements from the client to explore various therapeutic situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Therapeutic Scenarios:\n",
      "============================================================\n",
      "\n",
      "1. Anxiety and Overthinking\n",
      "   Opening: I've been feeling really anxious lately. My mind just keeps racing with all thes...\n",
      "\n",
      "2. Relationship Conflict\n",
      "   Opening: I had another argument with my partner yesterday. It feels like we keep having t...\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Define therapeutic conversation scenarios\n",
    "THERAPEUTIC_SCENARIOS = [\n",
    "    {\n",
    "        \"name\": \"Anxiety and Overthinking\",\n",
    "        \"opening\": \"I've been feeling really anxious lately. My mind just keeps racing with all these worst-case scenarios, and I can't seem to shut it off. It's affecting my sleep and my work.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Relationship Conflict\",\n",
    "        \"opening\": \"I had another argument with my partner yesterday. It feels like we keep having the same fight over and over. I don't know if we're just not compatible or if I'm doing something wrong.\"\n",
    "    },\n",
    "    # {\n",
    "    #     \"name\": \"Imposter Syndrome\",\n",
    "    #     \"opening\": \"I got promoted at work, but instead of feeling excited, I just feel terrified. I keep thinking they made a mistake choosing me, and everyone's going to realize I'm not actually good enough.\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"Burnout and Exhaustion\",\n",
    "    #     \"opening\": \"I'm so tired all the time. I used to love my job, but now just thinking about work makes me feel drained. I don't know if I should push through or if something needs to change.\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"Difficult Decision\",\n",
    "    #     \"opening\": \"I've been offered a job in another city. It's a great opportunity, but it would mean leaving my family and friends. I keep going back and forth, and I can't decide what's right.\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"Grief and Loss\",\n",
    "    #     \"opening\": \"It's been six months since I lost my dad, and people keep telling me I should be 'moving on.' But some days it hits me just as hard as it did in the beginning.\"\n",
    "    # }\n",
    "]\n",
    "\n",
    "print(\"üìã Therapeutic Scenarios:\")\n",
    "print(\"=\"*60)\n",
    "for i, scenario in enumerate(THERAPEUTIC_SCENARIOS, 1):\n",
    "    print(f\"\\n{i}. {scenario['name']}\")\n",
    "    print(f\"   Opening: {scenario['opening'][:80]}...\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Run Multi-Agent Therapeutic Conversations\n",
    "\n",
    "This will run conversations for each scenario with cognitive action detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_tkinter'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthird_party\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mliminal_backrooms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ai_turn\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthird_party\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mliminal_backrooms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AI_MODELS\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/ment_helth/brije/third_party/liminal_backrooms/main.py:21\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     TURN_DELAY,\n\u001b[32m      8\u001b[39m     AI_MODELS,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     SHARE_CHAIN_OF_THOUGHT\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshared_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     call_claude_api,\n\u001b[32m     15\u001b[39m     call_openrouter_api,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     call_gemma_api\n\u001b[32m     20\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgui\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AIGUI, create_gui, run_gui\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_image_message\u001b[39m(message: \u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns True if 'message' contains a base64 image in its 'content' list.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/ment_helth/brije/third_party/liminal_backrooms/gui.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageEnhance, ImageTk\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtkinter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtk\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtkinter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m scrolledtext, ttk, filedialog\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/ment_helth/brije/.venv/lib/python3.11/site-packages/PIL/ImageTk.py:29\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# The Python Imaging Library.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# $Id$\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# See the README file for information on usage and redistribution.\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtkinter\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BytesIO\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tkinter/__init__.py:38\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtypes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_tkinter\u001b[39;00m \u001b[38;5;66;03m# If this fails your Python may not be configured for Tk\u001b[39;00m\n\u001b[32m     39\u001b[39m TclError = _tkinter.TclError\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtkinter\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named '_tkinter'"
     ]
    }
   ],
   "source": [
    "from third_party.liminal_backrooms.main import ai_turn\n",
    "from third_party.liminal_backrooms.config import AI_MODELS\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def run_therapeutic_conversation(scenario, num_turns=3):\n",
    "    \"\"\"\n",
    "    Run a therapeutic conversation for a given scenario.\n",
    "    \n",
    "    Args:\n",
    "        scenario: Dict with 'name' and 'opening' keys\n",
    "        num_turns: Number of conversation turns (default 8 = 4 exchanges)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"SCENARIO: {scenario['name']}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nClient's opening: {scenario['opening']}\")\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    \n",
    "    # Configuration\n",
    "    therapist_model = \"Gemma 3 4B (with Probes)\"\n",
    "    client_model = \"Gemma 3 4B (with Probes)\"\n",
    "    \n",
    "    # Get system prompts\n",
    "    prompt_pair = \"Therapeutic Session - Therapist and Client\"\n",
    "    therapist_prompt = SYSTEM_PROMPT_PAIRS[prompt_pair][\"AI_1\"]\n",
    "    client_prompt = SYSTEM_PROMPT_PAIRS[prompt_pair][\"AI_2\"]\n",
    "    \n",
    "    # Initialize conversation with client's opening\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": scenario['opening']\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Run conversation turns\n",
    "    for turn in range(num_turns):\n",
    "        # Alternate between therapist (AI-1) and client (AI-2)\n",
    "        is_therapist = (turn % 2 == 0)\n",
    "        ai_name = \"Therapist\" if is_therapist else \"Client\"\n",
    "        model = therapist_model if is_therapist else client_model\n",
    "        system_prompt = therapist_prompt if is_therapist else client_prompt\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TURN {turn + 1}: {ai_name}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Run the AI turn\n",
    "        conversation = ai_turn(\n",
    "            ai_name=ai_name,\n",
    "            conversation=conversation,\n",
    "            model=model,\n",
    "            system_prompt=system_prompt,\n",
    "            gui=None\n",
    "        )\n",
    "        \n",
    "        # Display the latest response\n",
    "        latest = conversation[-1]\n",
    "        print(f\"\\n{ai_name}:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(latest.get('content', ''))\n",
    "        \n",
    "        # Display cognitive action predictions if available\n",
    "        if 'predictions' in latest:\n",
    "            print(\"\\n\" + \"-\" * 40)\n",
    "            print(\"üß† COGNITIVE ACTIONS DETECTED:\")\n",
    "            print(\"-\" * 40)\n",
    "            predictions = latest['predictions']\n",
    "            for i, pred in enumerate(predictions[:5], 1):  # Show top 5\n",
    "                action = pred.get('action', 'Unknown')\n",
    "                confidence = pred.get('confidence', 0.0)\n",
    "                is_active = pred.get('is_active', False)\n",
    "                marker = \"‚úì\" if is_active else \"‚óã\"\n",
    "                print(f\"  {marker} {i}. {action:35s} {confidence:6.1%}  {'[ACTIVE]' if is_active else ''}\")\n",
    "        \n",
    "        # Small delay between turns\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Save conversation\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = Path('output/therapeutic_conversations')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    output_file = output_dir / f\"{scenario['name'].replace(' ', '_')}_{timestamp}.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump({\n",
    "            'scenario': scenario,\n",
    "            'conversation': conversation,\n",
    "            'metadata': {\n",
    "                'therapist_model': therapist_model,\n",
    "                'client_model': client_model,\n",
    "                'num_turns': num_turns,\n",
    "                'timestamp': timestamp\n",
    "            }\n",
    "        }, f, indent=2, default=str)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"‚úÖ Conversation saved to: {output_file}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return conversation, output_file\n",
    "\n",
    "print(\"‚úÖ Therapeutic conversation function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Run All Scenarios\n",
    "\n",
    "Run therapeutic conversations for all scenarios (6-10 turns each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure number of turns\n",
    "NUM_TURNS = 8  # 8 turns = 4 therapist responses + 4 client responses\n",
    "\n",
    "print(f\"Running {len(THERAPEUTIC_SCENARIOS)} therapeutic scenarios...\")\n",
    "print(f\"Each conversation will have {NUM_TURNS} turns ({NUM_TURNS//2} exchanges)\\n\")\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i, scenario in enumerate(THERAPEUTIC_SCENARIOS, 1):\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"RUNNING SCENARIO {i}/{len(THERAPEUTIC_SCENARIOS)}\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    try:\n",
    "        conversation, output_file = run_therapeutic_conversation(scenario, num_turns=NUM_TURNS)\n",
    "        results.append({\n",
    "            'scenario': scenario['name'],\n",
    "            'success': True,\n",
    "            'output_file': str(output_file)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error in scenario '{scenario['name']}': {str(e)}\")\n",
    "        results.append({\n",
    "            'scenario': scenario['name'],\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "    \n",
    "    # Add delay between scenarios\n",
    "    if i < len(THERAPEUTIC_SCENARIOS):\n",
    "        print(\"\\n‚è∏Ô∏è  Pausing 5 seconds before next scenario...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\\n\" + \"#\"*80)\n",
    "print(\"ALL SCENARIOS COMPLETE\")\n",
    "print(\"#\"*80)\n",
    "print(f\"\\nTotal time: {elapsed_time/60:.1f} minutes\")\n",
    "print(f\"Successful: {sum(1 for r in results if r['success'])}/{len(results)}\")\n",
    "\n",
    "print(\"\\nüìä Results Summary:\")\n",
    "for result in results:\n",
    "    status = \"‚úÖ\" if result['success'] else \"‚ùå\"\n",
    "    print(f\"{status} {result['scenario']}\")\n",
    "    if result['success']:\n",
    "        print(f\"   Output: {result['output_file']}\")\n",
    "    else:\n",
    "        print(f\"   Error: {result['error']}\")\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Analyze Cognitive Actions Across Conversations\n",
    "\n",
    "Analyze which cognitive actions appear most frequently in therapist vs client responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# Load all saved conversations\n",
    "output_dir = Path('output/therapeutic_conversations')\n",
    "conversation_files = list(output_dir.glob('*.json'))\n",
    "\n",
    "if not conversation_files:\n",
    "    print(\"‚ö†Ô∏è  No conversation files found. Run the conversations first!\")\n",
    "else:\n",
    "    print(f\"üìä Analyzing {len(conversation_files)} conversations...\\n\")\n",
    "    \n",
    "    therapist_actions = Counter()\n",
    "    client_actions = Counter()\n",
    "    \n",
    "    for conv_file in conversation_files:\n",
    "        with open(conv_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        conversation = data['conversation']\n",
    "        \n",
    "        # Analyze each turn\n",
    "        for i, turn in enumerate(conversation):\n",
    "            if 'predictions' in turn:\n",
    "                # Therapist speaks on even turns (0, 2, 4...)\n",
    "                is_therapist = (i % 2 == 1)  # Skip initial user message\n",
    "                \n",
    "                for pred in turn['predictions']:\n",
    "                    if pred.get('is_active', False):\n",
    "                        action = pred['action']\n",
    "                        if is_therapist:\n",
    "                            therapist_actions[action] += 1\n",
    "                        else:\n",
    "                            client_actions[action] += 1\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"TOP COGNITIVE ACTIONS: THERAPIST\")\n",
    "    print(\"=\"*80)\n",
    "    for action, count in therapist_actions.most_common(15):\n",
    "        bar = \"‚ñà\" * (count // 2)\n",
    "        print(f\"{action:35s} {count:3d} {bar}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TOP COGNITIVE ACTIONS: CLIENT\")\n",
    "    print(\"=\"*80)\n",
    "    for action, count in client_actions.most_common(15):\n",
    "        bar = \"‚ñà\" * (count // 2)\n",
    "        print(f\"{action:35s} {count:3d} {bar}\")\n",
    "    \n",
    "    # Find unique actions\n",
    "    therapist_only = set(therapist_actions.keys()) - set(client_actions.keys())\n",
    "    client_only = set(client_actions.keys()) - set(therapist_actions.keys())\n",
    "    \n",
    "    if therapist_only:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"COGNITIVE ACTIONS UNIQUE TO THERAPIST\")\n",
    "        print(\"=\"*80)\n",
    "        for action in sorted(therapist_only):\n",
    "            print(f\"  ‚Ä¢ {action}\")\n",
    "    \n",
    "    if client_only:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"COGNITIVE ACTIONS UNIQUE TO CLIENT\")\n",
    "        print(\"=\"*80)\n",
    "        for action in sorted(client_only):\n",
    "            print(f\"  ‚Ä¢ {action}\")\n",
    "    \n",
    "    # Save analysis\n",
    "    analysis = {\n",
    "        'therapist_actions': dict(therapist_actions.most_common(20)),\n",
    "        'client_actions': dict(client_actions.most_common(20)),\n",
    "        'therapist_only': list(therapist_only),\n",
    "        'client_only': list(client_only)\n",
    "    }\n",
    "    \n",
    "    with open(output_dir / 'cognitive_action_analysis.json', 'w') as f:\n",
    "        json.dump(analysis, f, indent=2)\n",
    "    \n",
    "    print(\"\\n‚úÖ Analysis saved to: output/therapeutic_conversations/cognitive_action_analysis.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Visualize Cognitive Action Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if therapist_actions and client_actions:\n",
    "    # Get top actions from both\n",
    "    top_therapist = dict(therapist_actions.most_common(10))\n",
    "    top_client = dict(client_actions.most_common(10))\n",
    "    \n",
    "    # Combine and get unique actions\n",
    "    all_actions = set(list(top_therapist.keys()) + list(top_client.keys()))\n",
    "    \n",
    "    # Create comparison data\n",
    "    actions = sorted(all_actions)\n",
    "    therapist_counts = [top_therapist.get(a, 0) for a in actions]\n",
    "    client_counts = [top_client.get(a, 0) for a in actions]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Comparison bar chart\n",
    "    x = np.arange(len(actions))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[0].barh(x - width/2, therapist_counts, width, label='Therapist', color='steelblue', alpha=0.8)\n",
    "    axes[0].barh(x + width/2, client_counts, width, label='Client', color='coral', alpha=0.8)\n",
    "    axes[0].set_yticks(x)\n",
    "    axes[0].set_yticklabels(actions, fontsize=9)\n",
    "    axes[0].set_xlabel('Frequency', fontsize=11)\n",
    "    axes[0].set_title('Cognitive Action Comparison:\\nTherapist vs Client', fontsize=13, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3, axis='x')\n",
    "    axes[0].invert_yaxis()\n",
    "    \n",
    "    # Plot 2: Top 5 for each role\n",
    "    top5_therapist = dict(therapist_actions.most_common(5))\n",
    "    top5_client = dict(client_actions.most_common(5))\n",
    "    \n",
    "    y_pos = np.arange(len(top5_therapist) + len(top5_client) + 1)\n",
    "    colors = ['steelblue'] * len(top5_therapist) + ['white'] + ['coral'] * len(top5_client)\n",
    "    heights = list(top5_therapist.values()) + [0] + list(top5_client.values())\n",
    "    labels = list(top5_therapist.keys()) + [''] + list(top5_client.keys())\n",
    "    \n",
    "    axes[1].barh(y_pos, heights, color=colors, alpha=0.8, edgecolor='black')\n",
    "    axes[1].set_yticks(y_pos)\n",
    "    axes[1].set_yticklabels(labels, fontsize=9)\n",
    "    axes[1].set_xlabel('Frequency', fontsize=11)\n",
    "    axes[1].set_title('Top 5 Cognitive Actions\\nby Role', fontsize=13, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3, axis='x')\n",
    "    axes[1].invert_yaxis()\n",
    "    \n",
    "    # Add labels\n",
    "    axes[1].text(0.02, 0.95, 'Therapist', transform=axes[1].transAxes,\n",
    "                fontsize=11, fontweight='bold', color='steelblue',\n",
    "                verticalalignment='top')\n",
    "    axes[1].text(0.02, 0.35, 'Client', transform=axes[1].transAxes,\n",
    "                fontsize=11, fontweight='bold', color='coral',\n",
    "                verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'cognitive_action_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Visualization saved to: output/therapeutic_conversations/cognitive_action_comparison.png\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No cognitive action data available. Make sure probes are loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Run a Custom Scenario\n",
    "\n",
    "Create and run your own therapeutic conversation scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom scenario\n",
    "custom_scenario = {\n",
    "    \"name\": \"Custom Scenario\",\n",
    "    \"opening\": \"I feel like I'm stuck in a loop. Every time I try to make a change, I end up back where I started. I don't know what I'm doing wrong.\"\n",
    "}\n",
    "\n",
    "# Customize the number of turns (6-10 recommended)\n",
    "custom_num_turns = 10\n",
    "\n",
    "print(\"Running custom therapeutic conversation...\\n\")\n",
    "conversation, output_file = run_therapeutic_conversation(custom_scenario, num_turns=custom_num_turns)\n",
    "\n",
    "print(f\"\\n‚úÖ Custom conversation complete!\")\n",
    "print(f\"üìÅ Saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Summary and Next Steps\n",
    "\n",
    "This notebook explored therapeutic conversations with cognitive action detection:\n",
    "\n",
    "**What we learned:**\n",
    "- How therapists and clients use different cognitive actions\n",
    "- Which cognitive patterns emerge in different scenarios\n",
    "- How probe-based analysis can reveal thinking patterns\n",
    "\n",
    "**Next steps:**\n",
    "1. Analyze the saved conversations in `output/therapeutic_conversations/`\n",
    "2. Compare cognitive actions across different scenarios\n",
    "3. Experiment with different system prompts\n",
    "4. Try longer conversations (10-15 turns)\n",
    "5. Analyze specific therapeutic techniques used\n",
    "\n",
    "**Files generated:**\n",
    "- Individual conversation JSONs with full probe data\n",
    "- `cognitive_action_analysis.json` - Aggregate statistics\n",
    "- `cognitive_action_comparison.png` - Visualization"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
