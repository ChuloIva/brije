{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": "# Sentiment Probe Full Pipeline - Google Colab\n## 🆕 Regression-Based Continuous Sentiment Scoring\n\nComplete end-to-end pipeline for **regression-based sentiment probes** on Gemma 3 4B.\n\n### What makes this different?\n**Traditional approach**: Binary classification (0 or 1) with sigmoid probabilities  \n**Our approach**: **Linear regression** producing continuous sentiment scores (-∞ to +∞)\n\n### Why Regression?\n✅ **Smoother predictions** - No sigmoid compression  \n✅ **Natural intensity** - Magnitude reflects sentiment strength  \n✅ **Better granularity** - Detects subtle shifts in sentiment  \n✅ **Unbounded scores** - Can capture extreme emotions  \n\n### Pipeline Steps:\n1. ✅ Setup and clone repository\n2. 📝 Generate sentiment data (700 positive + 700 negative)\n3. 🚀 Capture activations from ALL layers (1-34) in batches\n4. 🎯 **Train regression-based sentiment probes** (MSE loss, continuous outputs)\n5. 📊 Visualize regression performance across layers\n6. 💾 Download trained models\n\n### Features:\n- **OOM Prevention**: Process layers in batches of 10 to avoid memory issues\n- **Progress Tracking**: Clear ETA and progress bars\n- **Auto-backup**: Save to Google Drive after each step\n- **Resume Capability**: Can resume from any batch if interrupted\n- **Continuous Scoring**: Get sentiment intensity scores, not just classifications\n\n### Requirements:\n- Google Colab with GPU (T4 or better)\n- Runtime: ~4-6 hours total\n- Hugging Face token for Gemma access\n\n### Example Outputs:\n```\nText: \"I'm absolutely thrilled about this opportunity!\"\nScore: +2.8  (Strong positive)\n\nText: \"Feeling a bit uncertain about the decision.\"\nScore: -0.4  (Slightly negative)\n\nText: \"This is the worst experience I've ever had.\"\nScore: -3.2  (Very strong negative)\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-gpu"
   },
   "source": [
    "## 1️⃣ Check GPU and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠️  WARNING: No GPU detected!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone-repo"
   },
   "source": [
    "## 2️⃣ Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone repository\n",
    "repo_url = \"https://github.com/ChuloIva/brije.git\"\n",
    "repo_name = \"brije\"\n",
    "\n",
    "if not os.path.exists(repo_name):\n",
    "    print(\"📥 Cloning repository...\")\n",
    "    !git clone {repo_url}\n",
    "    print(\"✅ Repository cloned\")\n",
    "else:\n",
    "    print(\"✅ Repository exists\")\n",
    "    !cd {repo_name} && git pull\n",
    "\n",
    "os.chdir(repo_name)\n",
    "print(f\"\\n📁 Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"📦 Installing dependencies...\\n\")\n",
    "!pip install -q torch transformers h5py scikit-learn tqdm matplotlib seaborn pandas\n",
    "\n",
    "# Install nnsight\n",
    "nnsight_dir = \"third_party/nnsight\"\n",
    "nnsight_repo = \"https://github.com/ndif-team/nnsight\"\n",
    "\n",
    "print(\"\\n📦 Setting up nnsight...\")\n",
    "if not os.path.exists(nnsight_dir) or not os.listdir(nnsight_dir):\n",
    "    os.makedirs(\"third_party\", exist_ok=True)\n",
    "    !git clone {nnsight_repo} {nnsight_dir}\n",
    "    print(\"   ✅ nnsight cloned\")\n",
    "else:\n",
    "    print(\"   ✅ nnsight exists\")\n",
    "\n",
    "!pip install -q -e {nnsight_dir}\n",
    "print(\"\\n✅ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mount-drive"
   },
   "source": [
    "## 3️⃣ Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create output directories\n",
    "drive_output_dir = '/content/drive/MyDrive/brije_sentiment_outputs'\n",
    "os.makedirs(drive_output_dir, exist_ok=True)\n",
    "os.makedirs(f\"{drive_output_dir}/data\", exist_ok=True)\n",
    "os.makedirs(f\"{drive_output_dir}/activations\", exist_ok=True)\n",
    "os.makedirs(f\"{drive_output_dir}/probes\", exist_ok=True)\n",
    "\n",
    "print(f\"✅ Google Drive mounted\")\n",
    "print(f\"   Outputs will be saved to: {drive_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf-login"
   },
   "source": [
    "## 4️⃣ Login to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hf"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "datagen-header"
   },
   "source": [
    "## 5️⃣ Generate Sentiment Data (700 Positive + 700 Negative)\n",
    "\n",
    "Uses Ollama locally or generates with Gemma on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "datagen-imports"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from dataclasses import dataclass, asdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "@dataclass\n",
    "class SentimentExample:\n",
    "    text: str\n",
    "    sentiment: str  # \"positive\" or \"negative\"\n",
    "    emotion: str\n",
    "\n",
    "# Sentiment definitions\n",
    "SENTIMENTS = {\n",
    "    \"positive\": {\n",
    "        \"emotions\": [\n",
    "            \"joy\", \"gratitude\", \"hope\", \"excitement\", \"love\", \n",
    "            \"pride\", \"contentment\", \"inspiration\", \"relief\", \"satisfaction\"\n",
    "        ]\n",
    "    },\n",
    "    \"negative\": {\n",
    "        \"emotions\": [\n",
    "            \"sadness\", \"anger\", \"fear\", \"disgust\", \"shame\",\n",
    "            \"anxiety\", \"frustration\", \"disappointment\", \"guilt\", \"loneliness\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "CONTEXTS = [\n",
    "    \"relationships\", \"work\", \"family\", \"friends\", \"health\",\n",
    "    \"achievements\", \"hobbies\", \"learning\", \"challenges\", \"life changes\"\n",
    "]\n",
    "\n",
    "print(\"✅ Sentiment definitions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "datagen-model"
   },
   "outputs": [],
   "source": [
    "# Load Gemma for data generation\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "print(\"Loading Gemma for data generation...\")\n",
    "model_name = \"google/gemma-3-4b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "gen_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "print(\"✅ Model loaded\")\n",
    "\n",
    "def generate_sentiment_example(sentiment: str, emotion: str, context: str) -> str:\n",
    "    \"\"\"Generate one sentiment example using Gemma\"\"\"\n",
    "    prompt = f\"\"\"Generate a brief first-person example expressing {sentiment} sentiment, specifically {emotion}, in the context of {context}.\n",
    "\n",
    "Requirements:\n",
    "- 2-3 sentences\n",
    "- First person (I, my, me)\n",
    "- Show genuine {emotion}, don't just state it\n",
    "- Natural and authentic\n",
    "\n",
    "Example only:\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(gen_model.device)\n",
    "    outputs = gen_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.9,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    return text.strip()\n",
    "\n",
    "print(\"✅ Generation function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "datagen-generate"
   },
   "outputs": [],
   "source": [
    "# Generate sentiment data\n",
    "print(\"=\"*70)\n",
    "print(\"GENERATING SENTIMENT DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "examples_per_sentiment = 700\n",
    "sentiment_data = {\"positive\": [], \"negative\": []}\n",
    "\n",
    "for sentiment in [\"positive\", \"negative\"]:\n",
    "    print(f\"\\nGenerating {sentiment} examples...\")\n",
    "    emotions = SENTIMENTS[sentiment][\"emotions\"]\n",
    "    \n",
    "    for i in tqdm(range(examples_per_sentiment), desc=sentiment.capitalize()):\n",
    "        emotion = random.choice(emotions)\n",
    "        context = random.choice(CONTEXTS)\n",
    "        \n",
    "        try:\n",
    "            text = generate_sentiment_example(sentiment, emotion, context)\n",
    "            if len(text) > 20:  # Valid example\n",
    "                sentiment_data[sentiment].append(\n",
    "                    SentimentExample(text=text, sentiment=sentiment, emotion=emotion)\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Cleanup every 50 examples\n",
    "        if i % 50 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n✅ Generated {len(sentiment_data['positive'])} positive and {len(sentiment_data['negative'])} negative examples\")\n",
    "\n",
    "# Clean up generation model\n",
    "del gen_model\n",
    "torch.cuda.empty_cache()\n",
    "print(\"✅ Freed generation model memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "datagen-save"
   },
   "outputs": [],
   "source": [
    "# Save sentiment data\n",
    "os.makedirs('third_party/datagen/generated_data', exist_ok=True)\n",
    "\n",
    "# Save separate files\n",
    "for sentiment in ['positive', 'negative']:\n",
    "    filename = f'third_party/datagen/generated_data/{sentiment}_sentiment_{len(sentiment_data[sentiment])}.jsonl'\n",
    "    with open(filename, 'w') as f:\n",
    "        for ex in sentiment_data[sentiment]:\n",
    "            f.write(json.dumps(asdict(ex)) + '\\n')\n",
    "    print(f\"✅ Saved {filename}\")\n",
    "\n",
    "# Save combined\n",
    "combined_file = 'third_party/datagen/generated_data/sentiment_combined_1400.jsonl'\n",
    "with open(combined_file, 'w') as f:\n",
    "    for sentiment in ['positive', 'negative']:\n",
    "        for ex in sentiment_data[sentiment]:\n",
    "            f.write(json.dumps(asdict(ex)) + '\\n')\n",
    "\n",
    "print(f\"\\n✅ Saved combined file: {combined_file}\")\n",
    "\n",
    "# Backup to Drive\n",
    "!cp third_party/datagen/generated_data/*.jsonl {drive_output_dir}/data/\n",
    "print(\"✅ Backed up to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "capture-header"
   },
   "source": [
    "## 6️⃣ Capture Activations from ALL Layers (1-34)\n",
    "\n",
    "Process in batches of 10 layers to avoid OOM:\n",
    "- Batch 1: Layers 1-10\n",
    "- Batch 2: Layers 11-20\n",
    "- Batch 3: Layers 21-30\n",
    "- Batch 4: Layers 31-34\n",
    "\n",
    "**Note**: You can skip already captured layers (21-30) by modifying the batches list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "capture-config"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Configuration\n",
    "CAPTURE_CONFIG = {\n",
    "    'model': 'google/gemma-3-4b-it',\n",
    "    'dataset': combined_file,\n",
    "    'device': 'auto',\n",
    "    'batch_size': 1000,\n",
    "    \n",
    "    # Define layer batches (10 layers each to avoid OOM)\n",
    "    'layer_batches': [\n",
    "        list(range(1, 11)),   # Batch 1: Layers 1-10\n",
    "        list(range(11, 21)),  # Batch 2: Layers 11-20\n",
    "        list(range(21, 31)),  # Batch 3: Layers 21-30 (already done, can skip)\n",
    "        list(range(31, 35))   # Batch 4: Layers 31-34\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Remove batch 3 if you already have layers 21-30 from cognitive actions\n",
    "# CAPTURE_CONFIG['layer_batches'] = [b for i, b in enumerate(CAPTURE_CONFIG['layer_batches']) if i != 2]\n",
    "\n",
    "print(\"Capture configuration:\")\n",
    "print(f\"  Model: {CAPTURE_CONFIG['model']}\")\n",
    "print(f\"  Dataset: {CAPTURE_CONFIG['dataset']}\")\n",
    "print(f\"  Total batches: {len(CAPTURE_CONFIG['layer_batches'])}\")\n",
    "print(f\"  Total layers: {sum(len(b) for b in CAPTURE_CONFIG['layer_batches'])}\")\n",
    "print(\"\\nBatches:\")\n",
    "for i, batch in enumerate(CAPTURE_CONFIG['layer_batches'], 1):\n",
    "    print(f\"  Batch {i}: Layers {batch[0]}-{batch[-1]} ({len(batch)} layers)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "capture-run"
   },
   "outputs": [],
   "source": [
    "# Run activation capture for each batch\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING ACTIVATION CAPTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "total_start = time.time()\n",
    "\n",
    "for batch_idx, layer_batch in enumerate(CAPTURE_CONFIG['layer_batches'], 1):\n",
    "    batch_start = time.time()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"BATCH {batch_idx}/{len(CAPTURE_CONFIG['layer_batches'])}: Layers {layer_batch[0]}-{layer_batch[-1]}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Build command\n",
    "    cmd = [\n",
    "        'python', 'src/probes/capture_activations.py',\n",
    "        '--dataset', CAPTURE_CONFIG['dataset'],\n",
    "        '--output-dir', 'data/activations/sentiment',\n",
    "        '--model', CAPTURE_CONFIG['model'],\n",
    "        '--layers', *[str(l) for l in layer_batch],\n",
    "        '--device', CAPTURE_CONFIG['device'],\n",
    "        '--format', 'hdf5',\n",
    "        '--single-pass',  # Optimized mode\n",
    "        '--batch-size', str(CAPTURE_CONFIG['batch_size'])\n",
    "    ]\n",
    "    \n",
    "    # Run capture\n",
    "    !{' '.join(cmd)}\n",
    "    \n",
    "    batch_elapsed = time.time() - batch_start\n",
    "    print(f\"\\n✅ Batch {batch_idx} complete in {batch_elapsed/60:.1f} minutes\")\n",
    "    \n",
    "    # Backup to Google Drive\n",
    "    print(\"\\n📥 Backing up to Google Drive...\")\n",
    "    !cp -r data/activations/sentiment/* {drive_output_dir}/activations/\n",
    "    print(\"✅ Backup complete\")\n",
    "    \n",
    "    # Cleanup between batches\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"🧹 Cleared GPU memory\\n\")\n",
    "\n",
    "total_elapsed = time.time() - total_start\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✅ ALL ACTIVATION CAPTURE COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total time: {total_elapsed/60:.1f} minutes ({total_elapsed/3600:.2f} hours)\")\n",
    "print(f\"Layers captured: {sum(len(b) for b in CAPTURE_CONFIG['layer_batches'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train-header"
   },
   "source": "## 7️⃣ Train Regression-Based Sentiment Probes\n\nTrain **linear regression probes** for each layer to predict continuous sentiment scores.\n\n### Why Regression Instead of Classification?\n\n**Classification (0 or 1)**:\n- Binary output: positive=1, negative=0\n- Sharp boundary, no nuance\n- Probabilities from sigmoid (0.0-1.0)\n\n**Regression (continuous scores)**:\n- Continuous output: -3 to +3 (unbounded)\n- Smooth transitions, captures intensity\n- Natural interpretation: negative scores = negative sentiment, positive scores = positive sentiment\n- Better for detecting subtle sentiment shifts\n\n### Score Interpretation:\n- **Strong negative**: -2.5 to -1.5\n- **Mild negative**: -1.5 to -0.5\n- **Neutral**: -0.5 to +0.5\n- **Mild positive**: +0.5 to +1.5\n- **Strong positive**: +1.5 to +2.5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-config"
   },
   "outputs": [],
   "source": "# Training configuration for REGRESSION probes\nTRAIN_CONFIG = {\n    'batch_size': 32,\n    'epochs': 50,\n    'learning_rate': 0.0005,\n    'weight_decay': 0.001,\n    'early_stopping_patience': 10,\n    'use_scheduler': True,\n    'device': 'auto'\n}\n\nprint(\"Regression Training Configuration:\")\nprint(\"=\"*60)\nfor key, value in TRAIN_CONFIG.items():\n    print(f\"  {key:25s}: {value}\")\nprint(\"=\"*60)\nprint(\"\\n💡 Using MSE loss (Mean Squared Error) for continuous prediction\")\nprint(\"💡 Targets: negative=-1, positive=+1 (will extrapolate beyond)\")\nprint(\"💡 Output: Unbounded continuous scores (smoother than sigmoid)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-run"
   },
   "outputs": [],
   "source": "# Get list of captured layers\nimport glob\n\nactivation_files = sorted(glob.glob('data/activations/sentiment/layer_*_activations.h5'))\ncaptured_layers = [int(f.split('layer_')[1].split('_')[0]) for f in activation_files]\n\nprint(f\"Found {len(captured_layers)} captured layers\")\nif captured_layers:\n    print(f\"  Layers: {captured_layers[:5]}...{captured_layers[-5:]}\" if len(captured_layers) > 10 else f\"  Layers: {captured_layers}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"🚀 TRAINING REGRESSION-BASED SENTIMENT PROBES\")\nprint(\"=\"*70)\nprint(\"Using: src/probes/sentiment_regression_probe.py\")\nprint(\"Output: Continuous sentiment scores (-∞ to +∞)\")\nprint(\"=\"*70 + \"\\n\")\n\ntrain_start = time.time()\nlayer_results = []\n\nfor layer_idx in captured_layers:\n    layer_start = time.time()\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"Training Layer {layer_idx} ({captured_layers.index(layer_idx) + 1}/{len(captured_layers)})\")\n    print(f\"{'='*70}\")\n    \n    activation_file = f\"data/activations/sentiment/layer_{layer_idx}_activations.h5\"\n    output_dir = f\"data/probes_regression/sentiment/layer_{layer_idx}\"\n    \n    if not os.path.exists(activation_file):\n        print(f\"⚠️  Skipping - activation file not found\")\n        continue\n    \n    # Build training command for REGRESSION probe\n    cmd = [\n        'python', 'src/probes/sentiment_regression_probe.py',\n        '--activations', activation_file,\n        '--output-dir', output_dir,\n        '--batch-size', str(TRAIN_CONFIG['batch_size']),\n        '--epochs', str(TRAIN_CONFIG['epochs']),\n        '--lr', str(TRAIN_CONFIG['learning_rate']),\n        '--weight-decay', str(TRAIN_CONFIG['weight_decay']),\n        '--early-stopping-patience', str(TRAIN_CONFIG['early_stopping_patience']),\n        '--device', TRAIN_CONFIG['device']\n    ]\n    \n    if not TRAIN_CONFIG['use_scheduler']:\n        cmd.append('--no-scheduler')\n    \n    # Run regression training\n    !{' '.join(cmd)}\n    \n    layer_elapsed = time.time() - layer_start\n    \n    # Load regression metrics\n    metrics_file = f\"{output_dir}/metrics.json\"\n    if os.path.exists(metrics_file):\n        with open(metrics_file, 'r') as f:\n            metrics = json.load(f)\n        \n        layer_results.append({\n            'layer': layer_idx,\n            'mse': metrics['mse'],\n            'mae': metrics['mae'],\n            'r2': metrics['r2'],\n            'accuracy': metrics['accuracy'],  # Binary accuracy at threshold 0\n            'score_range': (metrics['min_prediction'], metrics['max_prediction']),\n            'time_minutes': layer_elapsed / 60\n        })\n        \n        print(f\"\\n✅ Layer {layer_idx} complete in {layer_elapsed/60:.1f} minutes\")\n        print(f\"   MSE: {metrics['mse']:.4f}, MAE: {metrics['mae']:.4f}, \"\n              f\"R²: {metrics['r2']:.4f}, Accuracy: {metrics['accuracy']:.4f}\")\n        print(f\"   Score range: [{metrics['min_prediction']:.2f}, {metrics['max_prediction']:.2f}]\")\n    \n    # Backup to Drive\n    !mkdir -p {drive_output_dir}/probes_regression/\n    !cp -r {output_dir} {drive_output_dir}/probes_regression/\n\ntrain_elapsed = time.time() - train_start\n\nprint(f\"\\n{'='*70}\")\nprint(\"✅ ALL REGRESSION TRAINING COMPLETE\")\nprint(f\"{'='*70}\")\nprint(f\"Total time: {train_elapsed/60:.1f} minutes ({train_elapsed/3600:.2f} hours)\")\nprint(f\"Trained {len(layer_results)} layers with continuous sentiment scoring\")\nprint(f\"{'='*70}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viz-header"
   },
   "source": [
    "## 8️⃣ Visualize Performance Across Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-plot"
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\n\nif layer_results:\n    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n    \n    layers = [r['layer'] for r in layer_results]\n    r2_scores = [r['r2'] for r in layer_results]\n    mae_scores = [r['mae'] for r in layer_results]\n    accuracy_scores = [r['accuracy'] for r in layer_results]\n    score_ranges = [r['score_range'][1] - r['score_range'][0] for r in layer_results]\n    \n    # Plot 1: R² Score (coefficient of determination)\n    axes[0, 0].plot(layers, r2_scores, 'b-o', linewidth=2, markersize=6)\n    axes[0, 0].axhline(y=np.mean(r2_scores), color='r', linestyle='--', alpha=0.5, label='Mean')\n    axes[0, 0].set_xlabel('Layer', fontsize=12)\n    axes[0, 0].set_ylabel('R² Score', fontsize=12)\n    axes[0, 0].set_title('Regression Quality Across Layers (R²)', fontsize=14, fontweight='bold')\n    axes[0, 0].grid(True, alpha=0.3)\n    axes[0, 0].legend()\n    \n    # Mark best layer\n    best_idx = np.argmax(r2_scores)\n    axes[0, 0].annotate(f'Best: {layers[best_idx]}\\nR²={r2_scores[best_idx]:.4f}',\n                       xy=(layers[best_idx], r2_scores[best_idx]),\n                       xytext=(10, -20), textcoords='offset points',\n                       bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7),\n                       arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n    \n    # Plot 2: MAE (Mean Absolute Error)\n    axes[0, 1].plot(layers, mae_scores, 'g-s', linewidth=2, markersize=6)\n    axes[0, 1].axhline(y=np.mean(mae_scores), color='r', linestyle='--', alpha=0.5, label='Mean')\n    axes[0, 1].set_xlabel('Layer', fontsize=12)\n    axes[0, 1].set_ylabel('Mean Absolute Error', fontsize=12)\n    axes[0, 1].set_title('Prediction Error Across Layers (MAE)', fontsize=14, fontweight='bold')\n    axes[0, 1].grid(True, alpha=0.3)\n    axes[0, 1].legend()\n    axes[0, 1].invert_yaxis()  # Lower is better\n    \n    # Plot 3: Classification Accuracy (at threshold 0)\n    axes[1, 0].plot(layers, accuracy_scores, 'purple', marker='D', linewidth=2, markersize=6)\n    axes[1, 0].axhline(y=np.mean(accuracy_scores), color='r', linestyle='--', alpha=0.5, label='Mean')\n    axes[1, 0].set_xlabel('Layer', fontsize=12)\n    axes[1, 0].set_ylabel('Binary Accuracy', fontsize=12)\n    axes[1, 0].set_title('Classification Accuracy (threshold=0)', fontsize=14, fontweight='bold')\n    axes[1, 0].grid(True, alpha=0.3)\n    axes[1, 0].legend()\n    axes[1, 0].set_ylim([0.5, 1.0])\n    \n    # Plot 4: Score Range (dynamic range)\n    axes[1, 1].plot(layers, score_ranges, 'orange', marker='^', linewidth=2, markersize=6)\n    axes[1, 1].axhline(y=np.mean(score_ranges), color='r', linestyle='--', alpha=0.5, label='Mean')\n    axes[1, 1].set_xlabel('Layer', fontsize=12)\n    axes[1, 1].set_ylabel('Score Range', fontsize=12)\n    axes[1, 1].set_title('Dynamic Range of Predictions', fontsize=14, fontweight='bold')\n    axes[1, 1].grid(True, alpha=0.3)\n    axes[1, 1].legend()\n    \n    plt.tight_layout()\n    plt.savefig('sentiment_regression_layer_comparison.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    # Save to Drive\n    !cp sentiment_regression_layer_comparison.png {drive_output_dir}/\n    \n    print(\"\\n📊 Regression Performance Summary:\")\n    print(\"=\"*70)\n    print(f\"  Best layer (R²): {layers[best_idx]} (R²={r2_scores[best_idx]:.4f})\")\n    print(f\"  Mean R²: {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n    print(f\"  Mean MAE: {np.mean(mae_scores):.4f} ± {np.std(mae_scores):.4f}\")\n    print(f\"  Mean Accuracy: {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}\")\n    print(f\"  Mean Score Range: {np.mean(score_ranges):.2f} ± {np.std(score_ranges):.2f}\")\n    print(\"=\"*70)\n    \n    # Show example score ranges\n    print(\"\\n💡 Typical Sentiment Score Ranges by Layer:\")\n    for i, layer_idx in enumerate(layers[:5]):  # Show first 5\n        min_score, max_score = layer_results[i]['score_range']\n        print(f\"  Layer {layer_idx:2d}: [{min_score:+.2f}, {max_score:+.2f}]\")\n    if len(layers) > 5:\n        print(f\"  ... ({len(layers)-5} more layers)\")\n        \nelse:\n    print(\"⚠️  No results to visualize\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-header"
   },
   "source": [
    "## 9️⃣ Download Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download"
   },
   "outputs": [],
   "source": "from google.colab import files\n\n# Find best performing layer (by R² score)\nif layer_results:\n    best_layer = max(layer_results, key=lambda x: x['r2'])['layer']\n    \n    print(f\"Creating download package for best layer ({best_layer})...\")\n    print(f\"  R²: {max(layer_results, key=lambda x: x['r2'])['r2']:.4f}\")\n    print(f\"  MAE: {max(layer_results, key=lambda x: x['r2'])['mae']:.4f}\")\n    \n    # Create zip of best layer\n    best_layer_zip = f'sentiment_regression_probes_layer_{best_layer}.zip'\n    !cd data/probes_regression/sentiment && zip -r ../../../{best_layer_zip} layer_{best_layer}/ -q\n    \n    print(f\"\\n📥 Downloading {best_layer_zip}...\")\n    files.download(best_layer_zip)\n    \n    print(\"\\n✅ Download complete!\")\n    print(f\"\\nPackage contains:\")\n    print(f\"  • Layer {best_layer} regression sentiment probe\")\n    print(f\"  • Outputs continuous scores (not 0-1 probabilities!)\")\n    print(f\"  • Performance metrics (MSE, MAE, R²)\")\n    print(f\"  • Training history\")\n    \n    print(\"\\n💡 Usage example:\")\n    print(f\"```python\")\n    print(f\"# Load the probe\")\n    print(f\"probe, metadata = load_probe('sentiment_regression_probe.pth')\")\n    print(f\"\")\n    print(f\"# Get continuous sentiment score\")\n    print(f\"score = probe.predict(activations)  # Returns: -2.5 to +2.5 (unbounded)\")\n    print(f\"\")\n    print(f\"# Interpret:\")\n    print(f\"# Negative scores = negative sentiment\")\n    print(f\"# Positive scores = positive sentiment\")\n    print(f\"# Magnitude = intensity\")\n    print(f\"```\")\n    \n    print(\"\\n💡 To download all layers, uncomment and run:\")\n    print(\"  # !cd data/probes_regression && zip -r ../../sentiment_regression_all_layers.zip sentiment/ -q\")\n    print(\"  # files.download('sentiment_regression_all_layers.zip')\")\nelse:\n    print(\"⚠️  No trained models to download\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": "## 🎉 Pipeline Complete!\n\n### What was accomplished:\n1. ✅ Generated 1,400 sentiment examples (700 positive + 700 negative)\n2. ✅ Captured activations from all 34 Gemma layers\n3. ✅ **Trained REGRESSION-BASED sentiment probes for each layer**\n4. ✅ Visualized regression performance across layers\n5. ✅ Backed up everything to Google Drive\n\n### 🆕 Key Difference: Regression vs Classification\n\n**Traditional Binary Classification**:\n- Output: 0 or 1 (negative or positive)\n- Probabilities: 0.0-1.0 via sigmoid\n- Sharp boundary, no intensity information\n\n**Our Regression Approach** ⭐:\n- Output: Continuous scores (-∞ to +∞)\n- Natural interpretation: sign indicates polarity, magnitude indicates intensity\n- Smooth transitions, captures subtle sentiment shifts\n- Examples:\n  - `-2.5` = Very negative\n  - `-0.3` = Slightly negative\n  - `+0.2` = Slightly positive\n  - `+2.8` = Very positive\n\n### Files saved to Google Drive:\n- `{drive_output_dir}/data/` - Generated sentiment data\n- `{drive_output_dir}/activations/` - Layer activations\n- `{drive_output_dir}/probes_regression/` - **Regression-based probes**\n- `{drive_output_dir}/sentiment_regression_layer_comparison.png` - Performance visualization\n\n### How to use the regression probes:\n\n```python\n# Load probe\nfrom src.probes.probe_models import load_probe\nprobe, metadata = load_probe('sentiment_regression_probe.pth')\n\n# Get activation from text\nfrom src.probes.capture_activations import ActivationCapture\ncapture = ActivationCapture('google/gemma-3-4b-it', layers_to_capture=[best_layer])\nactivation = capture.capture_single_example(text, best_layer)\n\n# Predict continuous sentiment score\nscore = probe.predict(activation.unsqueeze(0))\n# Returns: tensor([[-1.85]]) for negative or tensor([[+2.31]]) for positive\n\n# Interpret the score:\nif score < -1.5:\n    print(f\"Strong negative sentiment: {score:.2f}\")\nelif score < -0.5:\n    print(f\"Mild negative sentiment: {score:.2f}\")\nelif score < 0.5:\n    print(f\"Neutral sentiment: {score:.2f}\")\nelif score < 1.5:\n    print(f\"Mild positive sentiment: {score:.2f}\")\nelse:\n    print(f\"Strong positive sentiment: {score:.2f}\")\n```\n\n### Next steps:\n1. Download trained regression probes for local use\n2. Integrate with existing cognitive action probes\n3. Use continuous scores for more nuanced sentiment analysis\n4. Create visualizations showing sentiment intensity over time\n5. Experiment with different score thresholds for your application\n\n### Advantages of regression-based probes:\n✅ Smoother predictions (no sigmoid compression)  \n✅ Natural intensity interpretation  \n✅ Better for detecting subtle sentiment shifts  \n✅ Can detect extreme sentiments (scores beyond ±1)  \n✅ More suitable for continuous sentiment tracking"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}