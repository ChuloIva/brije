{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Token-Level Probe Inference\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Real-time probe output** as tokens are processed\n",
    "2. **Token-by-token activation tracking** - see exactly which token triggered which probe\n",
    "3. **Activation visualization** - see how probe confidence changes across tokens\n",
    "4. **Export functionality** - save activation data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Set AMD GPU environment variables BEFORE importing torch\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def detect_amd_gpu():\n",
    "    try:\n",
    "        result = subprocess.run(['lspci'], capture_output=True, text=True, timeout=2)\n",
    "        return 'Advanced Micro Devices' in result.stdout\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "if detect_amd_gpu():\n",
    "    print(\"AMD GPU detected - configuring ROCm\")\n",
    "    os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"11.0.0\"\n",
    "    os.environ[\"HIP_VISIBLE_DEVICES\"] = \"0\"\n",
    "    os.environ[\"AMD_SERIALIZE_KERNEL\"] = \"3\"\n",
    "    os.environ[\"TORCH_USE_HIP_DSA\"] = \"1\"\n",
    "    os.environ[\"PYTORCH_ROCM_ARCH\"] = \"gfx1100\"\n",
    "    os.environ[\"PYTORCH_HIP_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "else:\n",
    "    print(\"No AMD GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Add src/probes to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src' / 'probes'))\n",
    "\n",
    "from streaming_probe_inference import StreamingProbeInferenceEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBES_BASE_DIR = Path('../data/probes_binary')\n",
    "MODEL_NAME = 'google/gemma-3-4b-it'\n",
    "\n",
    "engine = StreamingProbeInferenceEngine(\n",
    "    probes_base_dir=PROBES_BASE_DIR,\n",
    "    model_name=MODEL_NAME,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Real-Time Streaming Inference\n",
    "\n",
    "Watch probe activations appear **as each token is processed**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"After receiving feedback, I began reconsidering my approach.\n",
    "I realized I had been making assumptions without fully understanding the constraints.\"\"\"\n",
    "\n",
    "# Run with real-time output\n",
    "predictions = engine.predict_streaming(\n",
    "    text,\n",
    "    top_k=10,\n",
    "    threshold=0.1,\n",
    "    show_realtime=True  # Shows activations as they happen!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Token-Level Activations\n",
    "\n",
    "See **exactly which token** triggered each probe and **how strongly**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the top prediction\n",
    "engine.visualize_token_activations(predictions, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or visualize a specific action\n",
    "engine.visualize_token_activations(predictions, text, action_name='Reconsidering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect Token Activation Data\n",
    "\n",
    "Access detailed token-level data programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top prediction\n",
    "top_pred = predictions[0]\n",
    "\n",
    "print(f\"Action: {top_pred.action_name}\")\n",
    "print(f\"Final Confidence: {top_pred.confidence:.2%}\")\n",
    "print(f\"Peak Token: '{top_pred.peak_activation_token}' ({top_pred.peak_confidence:.2%})\")\n",
    "print(f\"\\nToken-by-token breakdown:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for tok in top_pred.token_activations:\n",
    "    print(f\"Pos {tok.token_position:3d} | {tok.token_text:15} | \"\n",
    "          f\"Confidence: {tok.confidence:.2%} | Active: {tok.is_active}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Multiple Texts\n",
    "\n",
    "See how different texts activate probes differently at the token level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_to_compare = [\n",
    "    \"Analyzing the quarterly data to identify key trends and patterns.\",\n",
    "    \"Brainstorming creative solutions and thinking outside the box.\",\n",
    "    \"Evaluating whether this approach will actually work in practice.\"\n",
    "]\n",
    "\n",
    "for i, text in enumerate(texts_to_compare, 1):\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"TEXT {i}: {text}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    preds = engine.predict_streaming(\n",
    "        text,\n",
    "        top_k=3,\n",
    "        threshold=0.05,\n",
    "        show_realtime=False  # Don't show token-by-token for comparison\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTop 3 actions:\")\n",
    "    for j, pred in enumerate(preds, 1):\n",
    "        print(f\"  {j}. {pred.action_name:30s} {pred.confidence:.2%}  \"\n",
    "              f\"(Peak at '{pred.peak_activation_token}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Token Activation Data\n",
    "\n",
    "Save activation data to CSV for external analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a text\n",
    "text = \"\"\"The quarterly numbers look concerning. Revenue is up but margins are down.\n",
    "We need to reconsider our pricing strategy.\"\"\"\n",
    "\n",
    "predictions = engine.predict_streaming(\n",
    "    text,\n",
    "    top_k=10,\n",
    "    threshold=0.05,\n",
    "    show_realtime=False\n",
    ")\n",
    "\n",
    "# Export to CSV\n",
    "output_path = Path('../output/token_activations.csv')\n",
    "output_path.parent.mkdir(exist_ok=True)\n",
    "engine.export_activations_csv(predictions, output_path)\n",
    "\n",
    "print(f\"\\n✓ Data exported to {output_path}\")\n",
    "print(\"\\nYou can now:\")\n",
    "print(\"  - Open in Excel/Google Sheets\")\n",
    "print(\"  - Load in pandas for analysis\")\n",
    "print(\"  - Create custom visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced: Find Peak Activation Tokens\n",
    "\n",
    "Find which specific tokens most strongly activate each cognitive action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"I was analyzing the problem, comparing different solutions, and evaluating their trade-offs.\n",
    "After reconsidering my assumptions, I realized I needed to brainstorm more creative approaches.\"\"\"\n",
    "\n",
    "predictions = engine.predict_streaming(\n",
    "    text,\n",
    "    top_k=20,\n",
    "    threshold=0.0,  # Get all predictions\n",
    "    show_realtime=False\n",
    ")\n",
    "\n",
    "print(\"\\nPeak Activation Tokens for Each Action:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for pred in predictions[:10]:  # Top 10\n",
    "    print(f\"{pred.action_name:30s} | Peak: '{pred.peak_activation_token:15}' ({pred.peak_confidence:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Custom Analysis: Activation Timeline\n",
    "\n",
    "See how cognitive actions evolve throughout the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The data looks wrong. I'm questioning my initial assumptions.\n",
    "Let me analyze this more carefully and compare it to previous results.\"\"\"\n",
    "\n",
    "predictions = engine.predict_streaming(\n",
    "    text,\n",
    "    top_k=5,\n",
    "    threshold=0.1,\n",
    "    show_realtime=False\n",
    ")\n",
    "\n",
    "# Show activation timeline\n",
    "print(\"\\nActivation Timeline:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get all unique token positions\n",
    "all_positions = set()\n",
    "for pred in predictions:\n",
    "    for tok in pred.token_activations:\n",
    "        all_positions.add(tok.token_position)\n",
    "\n",
    "# For each position, show which actions were active\n",
    "for pos in sorted(all_positions)[:20]:  # First 20 tokens\n",
    "    # Get token text (same across all predictions)\n",
    "    token_text = predictions[0].token_activations[pos].token_text\n",
    "    \n",
    "    print(f\"\\nPos {pos:3d} | Token: '{token_text:15}'\")\n",
    "    \n",
    "    # Show activations for each action at this position\n",
    "    for pred in predictions:\n",
    "        tok_act = pred.token_activations[pos]\n",
    "        if tok_act.is_active:\n",
    "            print(f\"         ✓ {pred.action_name:25s} {tok_act.confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✅ **Real-time probe output** - See activations as they happen\n",
    "2. ✅ **Token-level tracking** - Record which token triggered each probe\n",
    "3. ✅ **Activation visualization** - See patterns across tokens\n",
    "4. ✅ **Data export** - Save for external analysis\n",
    "5. ✅ **Timeline analysis** - Track how actions evolve through text\n",
    "\n",
    "### Use Cases:\n",
    "\n",
    "- **Debugging probes**: See exactly where activations happen\n",
    "- **Understanding text**: Identify which words/phrases trigger cognitive actions\n",
    "- **Model analysis**: Study how LLM representations encode cognitive processes\n",
    "- **Research**: Analyze activation patterns across different text types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
