{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brije: Cognitive Action Detection - Full Pipeline (Google Colab)\n",
    "\n",
    "Complete pipeline for training cognitive action probes on Gemma 3 4B.\n",
    "\n",
    "**This notebook will:**\n",
    "1. ‚úÖ Clone the Brije repository\n",
    "2. ‚úÖ Install all dependencies\n",
    "3. ‚úÖ Capture activations from Gemma 3 4B (~2-3 hours)\n",
    "4. ‚úÖ Train probes on captured activations (~20-30 minutes)\n",
    "5. ‚úÖ Test and evaluate performance\n",
    "6. ‚úÖ Download trained models to Google Drive\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab with A100 GPU (40GB VRAM recommended)\n",
    "- Runtime: ~3-4 hours total\n",
    "\n",
    "**Dataset:** 31,500 cognitive action examples across 45 actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check GPU and Setup Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: No GPU detected! This will be very slow on CPU.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone the repository\n",
    "repo_url = \"https://github.com/ChuloIva/brije.git\"\n",
    "repo_name = \"brije\"\n",
    "\n",
    "if not os.path.exists(repo_name):\n",
    "    print(\"üì• Cloning Brije repository...\")\n",
    "    !git clone {repo_url}\n",
    "    print(\"‚úÖ Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists\")\n",
    "    print(\"üîÑ Pulling latest changes...\")\n",
    "    !cd {repo_name} && git pull\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir(repo_name)\n",
    "print(f\"\\nüìÅ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"üì¶ Installing dependencies...\\n\")\n",
    "!pip install -q torch transformers h5py scikit-learn tqdm matplotlib seaborn\n",
    "\n",
    "# Install nnsight from third_party\n",
    "print(\"\\nüì¶ Installing nnsight...\")\n",
    "!pip install -q -e third_party/nnsight\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Mount Google Drive (for saving outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories in Google Drive for outputs\n",
    "drive_output_dir = '/content/drive/MyDrive/brije_outputs'\n",
    "os.makedirs(drive_output_dir, exist_ok=True)\n",
    "os.makedirs(f\"{drive_output_dir}/activations\", exist_ok=True)\n",
    "os.makedirs(f\"{drive_output_dir}/probes\", exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Outputs will be saved to: {drive_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dataset exists\n",
    "import glob\n",
    "\n",
    "dataset_path = \"third_party/datagen/generated_data\"\n",
    "datasets = glob.glob(f\"{dataset_path}/*.jsonl\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AVAILABLE DATASETS\")\n",
    "print(\"=\"*60)\n",
    "for ds in datasets:\n",
    "    size = os.path.getsize(ds) / 1e6\n",
    "    print(f\"  {os.path.basename(ds)} ({size:.2f} MB)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use the stratified combined dataset (31.5k examples)\n",
    "dataset_file = None\n",
    "for ds in datasets:\n",
    "    if 'stratified_combined' in ds or '31500' in ds:\n",
    "        dataset_file = ds\n",
    "        break\n",
    "\n",
    "if not dataset_file:\n",
    "    # Use any available dataset\n",
    "    dataset_file = datasets[0] if datasets else None\n",
    "\n",
    "if dataset_file:\n",
    "    print(f\"\\n‚úÖ Using dataset: {os.path.basename(dataset_file)}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No dataset found! You may need to generate data first.\")\n",
    "    print(\"See: third_party/datagen/README.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Configure Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'model': 'google/gemma-3-4b-it',\n",
    "    'dataset': dataset_file,\n",
    "    'layers_to_capture': [7, 14, 21, 27],  # Evenly spaced layers\n",
    "    'target_layer': 27,  # Layer to train probe on\n",
    "    'probe_type': 'multihead',  # 'linear' or 'multihead'\n",
    "    'batch_size': 32,\n",
    "    'epochs': 20,\n",
    "    'learning_rate': 0.001,\n",
    "    'device': 'auto',\n",
    "    'max_examples': None,  # None = use all examples, or set a number for quick test\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PIPELINE CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# For quick testing (uncomment to test with smaller dataset)\n",
    "# CONFIG['max_examples'] = 1000\n",
    "# CONFIG['epochs'] = 5\n",
    "# CONFIG['layers_to_capture'] = [27]  # Just one layer for quick test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Step 1: Capture Activations (~2-3 hours)\n",
    "\n",
    "This extracts hidden states from Gemma 3 4B at specified layers.\n",
    "\n",
    "**‚è∞ Expected time:** ~2-3 hours for full dataset (31.5k examples)\n",
    "\n",
    "**üíæ Memory:** ~12-16 GB VRAM peak usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: CAPTURING ACTIVATIONS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {CONFIG['model']}\")\n",
    "print(f\"Layers: {CONFIG['layers_to_capture']}\")\n",
    "print(f\"Dataset: {os.path.basename(CONFIG['dataset'])}\")\n",
    "print(\"\\n‚è∞ This will take 2-3 hours. Progress will be displayed below.\")\n",
    "print(\"üí° Activations are cached, so re-running is instant!\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Build command\n",
    "cmd = [\n",
    "    'python', 'src/probes/capture_activations.py',\n",
    "    '--dataset', CONFIG['dataset'],\n",
    "    '--output-dir', 'data/activations',\n",
    "    '--model', CONFIG['model'],\n",
    "    '--layers', *[str(l) for l in CONFIG['layers_to_capture']],\n",
    "    '--device', CONFIG['device'],\n",
    "    '--format', 'hdf5'\n",
    "]\n",
    "\n",
    "if CONFIG['max_examples']:\n",
    "    cmd.extend(['--max-examples', str(CONFIG['max_examples'])])\n",
    "\n",
    "# Run capture\n",
    "!{' '.join(cmd)}\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Activation capture completed in {elapsed/3600:.2f} hours ({elapsed/60:.1f} minutes)\")\n",
    "\n",
    "# Copy to Google Drive for backup\n",
    "print(\"\\nüì• Backing up activations to Google Drive...\")\n",
    "!cp -r data/activations/* {drive_output_dir}/activations/\n",
    "print(\"‚úÖ Backup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Step 2: Train Probe (~20-30 minutes)\n",
    "\n",
    "Train a probe to detect cognitive actions from the captured activations.\n",
    "\n",
    "**‚è∞ Expected time:** 15-30 minutes\n",
    "\n",
    "**üéØ Expected accuracy:** 70-85% (45-way classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: TRAINING PROBE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Layer: {CONFIG['target_layer']}\")\n",
    "print(f\"Probe type: {CONFIG['probe_type']}\")\n",
    "print(f\"Epochs: {CONFIG['epochs']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(\"\\n‚è∞ This will take 15-30 minutes.\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Build command\n",
    "activation_file = f\"data/activations/layer_{CONFIG['target_layer']}_activations.h5\"\n",
    "\n",
    "cmd = [\n",
    "    'python', 'src/probes/train_probes.py',\n",
    "    '--activations', activation_file,\n",
    "    '--output-dir', 'data/probes',\n",
    "    '--model-type', CONFIG['probe_type'],\n",
    "    '--batch-size', str(CONFIG['batch_size']),\n",
    "    '--epochs', str(CONFIG['epochs']),\n",
    "    '--lr', str(CONFIG['learning_rate']),\n",
    "    '--device', CONFIG['device']\n",
    "]\n",
    "\n",
    "# Run training\n",
    "!{' '.join(cmd)}\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Probe training completed in {elapsed/60:.1f} minutes\")\n",
    "\n",
    "# Copy to Google Drive\n",
    "print(\"\\nüì• Backing up trained probe to Google Drive...\")\n",
    "!cp -r data/probes/* {drive_output_dir}/probes/\n",
    "print(\"‚úÖ Backup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ View Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load test metrics\n",
    "metrics_file = 'data/probes/test_metrics.json'\n",
    "if os.path.exists(metrics_file):\n",
    "    with open(metrics_file, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TEST PERFORMANCE METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Test Accuracy:     {metrics['test_accuracy']:.2%}\")\n",
    "    print(f\"Macro F1 Score:    {metrics['macro_f1']:.4f}\")\n",
    "    print(f\"Top-3 Accuracy:    {metrics['top3_accuracy']:.2%}\")\n",
    "    print(f\"Top-5 Accuracy:    {metrics['top5_accuracy']:.2%}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Show best and worst classes\n",
    "    if 'per_class_f1' in metrics:\n",
    "        per_class = metrics['per_class_f1']\n",
    "        sorted_classes = sorted(per_class.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(\"\\nBest performing actions:\")\n",
    "        for action, f1 in sorted_classes[:5]:\n",
    "            print(f\"  {action:30s} F1: {f1:.3f}\")\n",
    "        \n",
    "        print(\"\\nWorst performing actions:\")\n",
    "        for action, f1 in sorted_classes[-5:]:\n",
    "            print(f\"  {action:30s} F1: {f1:.3f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Metrics file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Step 3: Test Probe Inference\n",
    "\n",
    "Test the trained probe on sample texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample texts\n",
    "test_texts = [\n",
    "    \"After receiving feedback, she began reconsidering her initial approach to the problem.\",\n",
    "    \"He was analyzing the data to find patterns and correlations between variables.\",\n",
    "    \"They started generating creative ideas for solving the design challenge.\",\n",
    "    \"She was evaluating different strategies to determine the most effective one.\",\n",
    "    \"He tried to recall the specific details from the previous meeting.\"\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INFERENCE EXAMPLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f\"\\nüìù Text: {text}\")\n",
    "    \n",
    "    cmd = [\n",
    "        'python', 'src/probes/probe_inference.py',\n",
    "        '--probe', 'data/probes/best_probe.pth',\n",
    "        '--model', CONFIG['model'],\n",
    "        '--layer', str(CONFIG['target_layer']),\n",
    "        '--text', text,\n",
    "        '--top-k', '3'\n",
    "    ]\n",
    "    \n",
    "    !{' '.join(cmd)}\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Visualize Training History (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "history_file = 'data/probes/training_history.json'\n",
    "if os.path.exists(history_file):\n",
    "    with open(history_file, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Plot loss\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].plot(epochs, history['train_loss'], 'b-', label='Train Loss')\n",
    "    axes[0].plot(epochs, history['val_loss'], 'r-', label='Val Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    axes[1].plot(epochs, history['train_acc'], 'b-', label='Train Accuracy')\n",
    "    axes[1].plot(epochs, history['val_acc'], 'r-', label='Val Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/probes/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Training curves saved to: data/probes/training_curves.png\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Training history not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Download Trained Models\n",
    "\n",
    "Download the trained probe and metrics for local use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Create a zip file with all outputs\n",
    "output_zip = 'brije_trained_probe.zip'\n",
    "\n",
    "print(\"üì¶ Creating download package...\")\n",
    "!cd data && zip -r ../{output_zip} probes/\n",
    "\n",
    "print(f\"\\n‚úÖ Package created: {output_zip}\")\n",
    "print(f\"Size: {os.path.getsize(output_zip) / 1e6:.2f} MB\")\n",
    "print(\"\\nüì• Starting download...\")\n",
    "\n",
    "files.download(output_zip)\n",
    "\n",
    "print(\"\\n‚úÖ Download complete!\")\n",
    "print(\"\\nPackage contains:\")\n",
    "print(\"  ‚Ä¢ best_probe.pth - Best performing model\")\n",
    "print(\"  ‚Ä¢ final_probe.pth - Final epoch model\")\n",
    "print(\"  ‚Ä¢ test_metrics.json - Performance metrics\")\n",
    "print(\"  ‚Ä¢ training_history.json - Training curves\")\n",
    "print(\"  ‚Ä¢ confusion_matrix.png - Confusion matrix plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üéâ PIPELINE COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úÖ What was accomplished:\")\n",
    "print(\"  1. Captured activations from Gemma 3 4B\")\n",
    "print(\"  2. Trained probe for cognitive action detection\")\n",
    "print(\"  3. Evaluated on test set\")\n",
    "print(\"  4. Saved all outputs to Google Drive\")\n",
    "print(\"\\nüìÇ Outputs saved to:\")\n",
    "print(f\"  ‚Ä¢ Local: {os.getcwd()}/data/\")\n",
    "print(f\"  ‚Ä¢ Google Drive: {drive_output_dir}\")\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"  1. Download the trained probe (see cell above)\")\n",
    "print(\"  2. Use probe in liminal_backrooms GUI\")\n",
    "print(\"  3. Test on your own texts\")\n",
    "print(\"  4. Train on different layers for comparison\")\n",
    "print(\"\\nüìö Documentation:\")\n",
    "print(\"  ‚Ä¢ README.md - Full documentation\")\n",
    "print(\"  ‚Ä¢ QUICK_REFERENCE.md - Command cheat sheet\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
