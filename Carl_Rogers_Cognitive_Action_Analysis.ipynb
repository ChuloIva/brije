{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carl Rogers Therapy Transcripts - Cognitive Action Analysis\n",
    "\n",
    "This notebook analyzes therapy transcripts from Carl Rogers using universal cognitive action probe inference.\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Extract transcripts from PDF with speaker identification (therapist/client)\n",
    "- ‚úÖ Universal probe inference for cognitive action detection\n",
    "- ‚úÖ Cognitive action network visualization per transcript\n",
    "- ‚úÖ Combined network analysis across all transcripts\n",
    "- ‚úÖ Separate therapist and client network analysis\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab with GPU (T4 or better)\n",
    "- ~15 GB VRAM\n",
    "- Runtime: ~2-3 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check GPU and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: No GPU detected! This will be very slow on CPU.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone the repository\n",
    "repo_url = \"https://github.com/ChuloIva/brije.git\"\n",
    "repo_name = \"brije\"\n",
    "\n",
    "if not os.path.exists(repo_name):\n",
    "    print(\"üì• Cloning Brije repository...\")\n",
    "    !git clone {repo_url}\n",
    "    print(\"‚úÖ Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists\")\n",
    "    print(\"üîÑ Pulling latest changes...\")\n",
    "    !cd {repo_name} && git pull\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir(repo_name)\n",
    "print(f\"\\nüìÅ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"üì¶ Installing dependencies...\\n\")\n",
    "\n",
    "# Core dependencies\n",
    "print(\"Installing core packages...\")\n",
    "!pip install -q torch transformers h5py scikit-learn tqdm matplotlib seaborn pandas networkx pypdf2 pdfplumber\n",
    "\n",
    "# Clone and install nnsight\n",
    "nnsight_dir = \"third_party/nnsight\"\n",
    "nnsight_repo = \"https://github.com/ndif-team/nnsight\"\n",
    "\n",
    "print(\"\\nüì¶ Setting up nnsight...\")\n",
    "if not os.path.exists(nnsight_dir) or not os.listdir(nnsight_dir):\n",
    "    print(\"   Cloning nnsight repository...\")\n",
    "    os.makedirs(\"third_party\", exist_ok=True)\n",
    "    !git clone {nnsight_repo} {nnsight_dir}\n",
    "    print(\"   ‚úÖ nnsight repository cloned\")\n",
    "else:\n",
    "    print(\"   ‚úÖ nnsight repository already exists\")\n",
    "\n",
    "# Install nnsight\n",
    "print(\"   Installing nnsight...\")\n",
    "!pip install -q -e {nnsight_dir}\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Verify Pre-trained Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Check for probes in the repository\n",
    "local_probes_dir = 'data/probes_binary'\n",
    "\n",
    "probe_dirs = glob.glob(f'{local_probes_dir}/layer_*')\n",
    "\n",
    "if probe_dirs:\n",
    "    print(\"‚úÖ Found pre-trained probes in repository\")\n",
    "    print(f\"\\nüìä Available probe layers: {len(probe_dirs)}\")\n",
    "    \n",
    "    for probe_dir in sorted(probe_dirs)[:5]:\n",
    "        layer_num = os.path.basename(probe_dir).replace('layer_', '')\n",
    "        probe_files = glob.glob(f\"{probe_dir}/probe_*.pth\")\n",
    "        print(f\"   Layer {layer_num}: {len(probe_files)} probes\")\n",
    "    \n",
    "    if len(probe_dirs) > 5:\n",
    "        print(f\"   ... and {len(probe_dirs) - 5} more layers\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No probes found in:\", local_probes_dir)\n",
    "    print(\"\\nüí° Please train probes first using:\")\n",
    "    print(\"   Brije_Full_Pipeline_Colab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Login to Hugging Face (for Gemma 3 4B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5Ô∏è‚É£ Load Pre-Parsed Transcripts\n\nThe transcripts have been pre-parsed from the raw PDF into clean CSV/JSON format.\n\n**Available formats:**\n- `all_sessions_combined.csv` - All sessions in flat CSV format\n- `all_sessions_combined.json` - All sessions with full metadata\n- Individual session files: `{session_name}_session.csv/json`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport pandas as pd\nfrom pathlib import Path\n\n# Path to parsed transcripts\ndata_dir = Path('output/carl_rogers_analysis')\ncsv_file = data_dir / 'all_sessions_combined.csv'\njson_file = data_dir / 'all_sessions_combined.json'\n\nprint(\"üì• Loading pre-parsed transcripts...\")\n\n# Load from CSV (flat format)\ndf = pd.read_csv(csv_file)\n\nprint(f\"‚úÖ Loaded {len(df)} total utterances from {df['session'].nunique()} sessions\")\n\n# Statistics\ntotal_utterances = len(df)\ntherapist_utterances = len(df[df['speaker'] == 'therapist'])\nclient_utterances = len(df[df['speaker'] == 'client'])\n\nprint(f\"\\nüìä Dataset Statistics:\")\nprint(f\"   Total utterances: {total_utterances}\")\nprint(f\"   Therapist (Rogers) utterances: {therapist_utterances}\")\nprint(f\"   Client utterances: {client_utterances}\")\nprint(f\"\\n   Sessions: {', '.join(df['session'].unique())}\")\n\n# Also load JSON for detailed metadata if needed\nwith open(json_file, 'r', encoding='utf-8') as f:\n    json_data = json.load(f)\n\nprint(f\"\\n   Years covered: {sorted(set(s['year'] for s in json_data['sessions']))}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Convert dataframe to transcript format for processing\nprint(\"=\" * 80)\nprint(\"SAMPLE TRANSCRIPTS\")\nprint(\"=\" * 80)\n\n# Create transcripts list from the parsed data\ntranscripts = []\n\nfor session_data in json_data['sessions']:\n    session_name = session_data['session_name']\n    session_df = df[df['session'] == session_name]\n    \n    utterances = []\n    for idx, row in session_df.iterrows():\n        utterances.append({\n            'utterance_id': idx,\n            'speaker': row['speaker'],\n            'speaker_name': row['speaker_name'],\n            'text': row['text'],\n            'turn_number': row['turn_number']\n        })\n    \n    transcripts.append({\n        'transcript_id': session_name,\n        'title': f\"{session_data['client_name']} Session ({session_data['year']})\",\n        'session_name': session_name,\n        'client_name': session_data['client_name'],\n        'year': session_data['year'],\n        'utterances': utterances\n    })\n\n# Show sample\nfor i, transcript in enumerate(transcripts[:3]):\n    print(f\"\\nüìÑ {transcript['session_name']}: {transcript['title']}\")\n    print(f\"   Total utterances: {len(transcript['utterances'])}\")\n    \n    therapist_count = sum(1 for u in transcript['utterances'] if u['speaker'] == 'therapist')\n    client_count = sum(1 for u in transcript['utterances'] if u['speaker'] == 'client')\n    print(f\"   Therapist: {therapist_count}, Client: {client_count}\")\n    \n    print(f\"\\n   First 5 utterances:\")\n    for utterance in transcript['utterances'][:5]:\n        speaker = \"THERAPIST\" if utterance['speaker'] == 'therapist' else \"CLIENT   \"\n        text = utterance['text'][:100] + \"...\" if len(utterance['text']) > 100 else utterance['text']\n        print(f\"      [{speaker}] {text}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Show transcript distribution\nprint(\"\\n\" + \"=\" * 80)\nprint(\"TRANSCRIPT DISTRIBUTION\")\nprint(\"=\" * 80)\n\nprint(f\"\\nAll {len(transcripts)} sessions:\")\nfor t in transcripts:\n    session_df = df[df['session'] == t['session_name']]\n    t_count = len(session_df[session_df['speaker'] == 'therapist'])\n    c_count = len(session_df[session_df['speaker'] == 'client'])\n    title_preview = t['title'][:45] + \"...\" if len(t['title']) > 45 else t['title']\n    print(f\"   {t['session_name']:15s} | {title_preview:48s} | Total: {len(session_df):3d} (T: {t_count:3d}, C: {c_count:3d})\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6Ô∏è‚É£ Optional: Quality Check\n\nVerify the parsed data looks correct."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Quality check - look for any parsing anomalies\nprint(\"üîç DATA QUALITY CHECK\\n\")\n\n# Check for very short or very long utterances\nshort_utterances = []\nlong_utterances = []\n\nfor idx, row in df.iterrows():\n    text_len = len(row['text'])\n    if text_len < 20:\n        short_utterances.append((row['session'], row['speaker'], text_len, row['text']))\n    if text_len > 1000:\n        long_utterances.append((row['session'], row['speaker'], text_len, row['text'][:100]))\n\nif short_utterances:\n    print(f\"‚ö†Ô∏è  Found {len(short_utterances)} very short utterances (< 20 chars)\")\n    print(\"   First 5 examples:\")\n    for session, speaker, length, text in short_utterances[:5]:\n        print(f\"      Session {session} [{speaker}] ({length} chars): {text}\")\n\nif long_utterances:\n    print(f\"\\nüìù Found {len(long_utterances)} very long utterances (> 1000 chars)\")\n    print(\"   These are usually complete therapy turns - normal for transcripts\")\n    \n# Check speaker balance\nprint(f\"\\nüìä Speaker balance per session:\")\nfor session_name in df['session'].unique():\n    session_df = df[df['session'] == session_name]\n    t_count = len(session_df[session_df['speaker'] == 'therapist'])\n    c_count = len(session_df[session_df['speaker'] == 'client'])\n    ratio = t_count / c_count if c_count > 0 else 0\n    print(f\"   {session_name:15s}: T/C ratio = {ratio:.2f} (T:{t_count:3d}, C:{c_count:3d})\")\n\nprint(f\"\\n‚úÖ Data quality check complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Initialize Universal Probe Inference Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src', 'probes'))\n",
    "\n",
    "from universal_multi_layer_inference import UniversalMultiLayerInferenceEngine\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize the engine\n",
    "print(\"üöÄ Initializing Universal Probe Inference Engine...\\n\")\n",
    "\n",
    "engine = UniversalMultiLayerInferenceEngine(\n",
    "    probes_base_dir=Path('data/probes_binary'),\n",
    "    model_name='google/gemma-3-4b-it',\n",
    "    layer_range=(21, 30)  # Layers 21-30\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Engine initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Run Cognitive Action Inference\n",
    "\n",
    "Analyze all utterances and detect cognitive actions.\n",
    "\n",
    "**Filtering:** We keep only high-confidence actions that appear on **>2 layers** OR have **100% confidence**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\nfrom tqdm import tqdm\nimport json\nfrom collections import defaultdict\n\nprint(\"üß† Running cognitive action inference...\\n\")\n\n# Create output directory\noutput_dir = Path('output/carl_rogers_analysis')\noutput_dir.mkdir(parents=True, exist_ok=True)\n\n# Process each transcript\nannotated_transcripts = []\nstart_time = time.time()\n\nfor transcript in tqdm(transcripts, desc=\"Processing transcripts\"):\n    annotated_utterances = []\n    \n    for utterance in tqdm(transcript['utterances'], desc=f\"  {transcript['session_name']}\", leave=False):\n        utterance_text = utterance['text']\n        \n        # Skip very short utterances\n        if len(utterance_text) < 10:\n            continue\n        \n        try:\n            # Run universal inference\n            action_preds = engine.predict_by_action(\n                utterance_text,\n                threshold=0.1,\n                aggregation=\"max\"\n            )\n            \n            # Get all layer predictions for filtering\n            all_layer_preds = engine.predict_all(\n                utterance_text,\n                threshold=0.1\n            )\n            \n            # Group by action with layer info\n            action_layer_map = defaultdict(list)\n            for pred in all_layer_preds:\n                if pred.is_active:\n                    action_layer_map[pred.action_name].append({\n                        'layer': pred.layer,\n                        'confidence': pred.confidence\n                    })\n            \n            # FILTER: Keep only actions with >2 layers OR 100% confidence\n            filtered_predictions = {}\n            for action_name, action_info in action_preds.items():\n                if not action_info.get('is_active', False):\n                    continue\n                \n                num_layers = len(action_layer_map.get(action_name, []))\n                max_confidence = max(\n                    [layer_info['confidence'] for layer_info in action_layer_map.get(action_name, [])],\n                    default=0\n                )\n                \n                if num_layers > 2 or max_confidence >= 1.0:\n                    filtered_predictions[action_name] = action_info\n            \n            annotated_utterances.append({\n                'utterance_id': utterance['utterance_id'],\n                'speaker': utterance['speaker'],\n                'text': utterance_text,\n                'predictions': filtered_predictions,\n                'action_layer_details': dict(action_layer_map)\n            })\n            \n        except Exception as e:\n            print(f\"\\n‚ö†Ô∏è  Error processing utterance: {e}\")\n            continue\n    \n    annotated_transcripts.append({\n        'transcript_id': transcript['transcript_id'],\n        'session_name': transcript['session_name'],\n        'title': transcript['title'],\n        'utterances': annotated_utterances\n    })\n\nelapsed_time = time.time() - start_time\n\nprint(f\"\\n‚úÖ Inference complete!\")\nprint(f\"   Time elapsed: {elapsed_time/3600:.2f} hours\")\nprint(f\"   Average time per transcript: {elapsed_time/len(transcripts):.2f} seconds\")\n\n# Save annotated transcripts\noutput_file = output_dir / 'annotated_transcripts.json'\nwith open(output_file, 'w') as f:\n    json.dump(annotated_transcripts, f, indent=2, default=str)\n\nprint(f\"\\nüíæ Saved to: {output_file}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Cognitive Action Network - Per Transcript\n",
    "\n",
    "Create network visualizations for each transcript (therapist and client separately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import networkx as nx\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n\nsns.set_style('whitegrid')\n\ndef create_cognitive_action_network(utterances, speaker_filter=None, min_edge_weight=2):\n    \"\"\"\n    Create a directed graph of cognitive action transitions.\n    \n    Args:\n        utterances: List of annotated utterances\n        speaker_filter: 'therapist' or 'client' to filter by speaker, None for all\n        min_edge_weight: Minimum number of transitions to include edge\n    \"\"\"\n    # Filter by speaker\n    if speaker_filter:\n        utterances = [u for u in utterances if u['speaker'] == speaker_filter]\n    \n    # Create graph\n    G = nx.DiGraph()\n    \n    # Count co-occurrences (actions appearing together) and transitions\n    edge_weights = Counter()\n    node_weights = Counter()\n    \n    # Add edges for co-occurrence within same utterance\n    for utterance in utterances:\n        actions = [action for action, data in utterance['predictions'].items() \n                  if data.get('is_active', False)]\n        \n        # Count node occurrences\n        for action in actions:\n            node_weights[action] += 1\n        \n        # Add edges for all pairs (co-occurrence)\n        for i, action1 in enumerate(actions):\n            for action2 in actions[i+1:]:\n                # Undirected co-occurrence\n                edge = tuple(sorted([action1, action2]))\n                edge_weights[edge] += 1\n    \n    # Add transitions between consecutive utterances\n    for i in range(len(utterances) - 1):\n        current_actions = [action for action, data in utterances[i]['predictions'].items() \n                          if data.get('is_active', False)]\n        next_actions = [action for action, data in utterances[i+1]['predictions'].items() \n                       if data.get('is_active', False)]\n        \n        for curr_action in current_actions:\n            for next_action in next_actions:\n                edge_weights[(curr_action, next_action)] += 1\n    \n    # Add nodes\n    for action, weight in node_weights.items():\n        G.add_node(action, weight=weight)\n    \n    # Add edges\n    for edge, weight in edge_weights.items():\n        if weight >= min_edge_weight:\n            G.add_edge(edge[0], edge[1], weight=weight)\n    \n    return G, node_weights, edge_weights\n\ndef visualize_network(G, title, output_path, top_n_nodes=20):\n    \"\"\"\n    Visualize cognitive action network.\n    \"\"\"\n    if len(G.nodes()) == 0:\n        print(f\"‚ö†Ô∏è  No nodes in graph for {title}\")\n        return\n    \n    # Get top N nodes by degree\n    node_degrees = dict(G.degree())\n    top_nodes = sorted(node_degrees.items(), key=lambda x: x[1], reverse=True)[:top_n_nodes]\n    top_node_names = [node for node, _ in top_nodes]\n    \n    # Create subgraph\n    G_sub = G.subgraph(top_node_names).copy()\n    \n    if len(G_sub.nodes()) == 0:\n        print(f\"‚ö†Ô∏è  No nodes after filtering for {title}\")\n        return\n    \n    # Layout\n    pos = nx.spring_layout(G_sub, k=2, iterations=50, seed=42)\n    \n    # Node sizes based on degree\n    node_sizes = [G_sub.degree(node) * 200 for node in G_sub.nodes()]\n    \n    # Edge widths based on weight\n    edges = G_sub.edges()\n    weights = [G_sub[u][v]['weight'] for u, v in edges]\n    max_weight = max(weights) if weights else 1\n    edge_widths = [w / max_weight * 5 for w in weights]\n    \n    # Draw\n    plt.figure(figsize=(16, 12))\n    \n    nx.draw_networkx_nodes(G_sub, pos, node_size=node_sizes, \n                          node_color='lightblue', alpha=0.7, \n                          edgecolors='black', linewidths=1.5)\n    \n    nx.draw_networkx_labels(G_sub, pos, font_size=9, font_weight='bold')\n    \n    nx.draw_networkx_edges(G_sub, pos, width=edge_widths, alpha=0.4,\n                          arrows=True, arrowsize=15, edge_color='gray',\n                          connectionstyle='arc3,rad=0.1')\n    \n    plt.title(title, fontsize=14, fontweight='bold')\n    plt.axis('off')\n    plt.tight_layout()\n    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n    plt.close()\n    \n    print(f\"‚úÖ Saved: {output_path}\")\n\nprint(\"üìä Creating cognitive action networks per transcript...\\n\")\n\n# Create networks for each transcript\nnetwork_dir = output_dir / 'networks'\nnetwork_dir.mkdir(exist_ok=True)\n\nfor transcript in annotated_transcripts:\n    session_name = transcript['session_name']\n    title = transcript['title']\n    utterances = transcript['utterances']\n    \n    print(f\"\\n{session_name}: {title}\")\n    \n    # Therapist network\n    G_therapist, node_weights_t, edge_weights_t = create_cognitive_action_network(\n        utterances, speaker_filter='therapist', min_edge_weight=1\n    )\n    \n    if len(G_therapist.nodes()) > 0:\n        visualize_network(\n            G_therapist,\n            f\"Therapist Cognitive Actions\\n{session_name}\",\n            network_dir / f\"{session_name}_therapist.png\"\n        )\n    \n    # Client network\n    G_client, node_weights_c, edge_weights_c = create_cognitive_action_network(\n        utterances, speaker_filter='client', min_edge_weight=1\n    )\n    \n    if len(G_client.nodes()) > 0:\n        visualize_network(\n            G_client,\n            f\"Client Cognitive Actions\\n{session_name}\",\n            network_dir / f\"{session_name}_client.png\"\n        )\n\nprint(\"\\n‚úÖ Per-transcript networks complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Combined Network Analysis\n",
    "\n",
    "Aggregate cognitive action networks across all transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Creating combined network analysis...\\n\")\n",
    "\n",
    "# Combine all utterances\n",
    "all_utterances = []\n",
    "for transcript in annotated_transcripts:\n",
    "    all_utterances.extend(transcript['utterances'])\n",
    "\n",
    "# Combined therapist network\n",
    "print(\"Creating combined therapist network...\")\n",
    "G_therapist_combined, node_weights_t, edge_weights_t = create_cognitive_action_network(\n",
    "    all_utterances, speaker_filter='therapist', min_edge_weight=3\n",
    ")\n",
    "\n",
    "visualize_network(\n",
    "    G_therapist_combined,\n",
    "    \"Therapist Cognitive Actions (All Transcripts)\",\n",
    "    output_dir / \"combined_therapist_network.png\",\n",
    "    top_n_nodes=25\n",
    ")\n",
    "\n",
    "# Combined client network\n",
    "print(\"Creating combined client network...\")\n",
    "G_client_combined, node_weights_c, edge_weights_c = create_cognitive_action_network(\n",
    "    all_utterances, speaker_filter='client', min_edge_weight=3\n",
    ")\n",
    "\n",
    "visualize_network(\n",
    "    G_client_combined,\n",
    "    \"Client Cognitive Actions (All Transcripts)\",\n",
    "    output_dir / \"combined_client_network.png\",\n",
    "    top_n_nodes=25\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Combined networks complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Network Statistics & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"NETWORK ANALYSIS STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def analyze_network(G, name):\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"   Nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"   Edges: {G.number_of_edges()}\")\n",
    "    print(f\"   Density: {nx.density(G):.3f}\")\n",
    "    \n",
    "    if G.number_of_nodes() > 0:\n",
    "        # Centrality measures\n",
    "        degree_centrality = nx.degree_centrality(G)\n",
    "        pagerank = nx.pagerank(G)\n",
    "        \n",
    "        print(f\"\\n   Top 10 by Degree Centrality:\")\n",
    "        for action, score in sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "            print(f\"      {action:30s} {score:.3f}\")\n",
    "        \n",
    "        print(f\"\\n   Top 10 by PageRank:\")\n",
    "        for action, score in sorted(pagerank.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "            print(f\"      {action:30s} {score:.3f}\")\n",
    "\n",
    "analyze_network(G_therapist_combined, \"THERAPIST (Combined)\")\n",
    "analyze_network(G_client_combined, \"CLIENT (Combined)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Comparison: Therapist vs Client Cognitive Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"THERAPIST VS CLIENT COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get action frequencies\n",
    "therapist_actions = Counter()\n",
    "client_actions = Counter()\n",
    "\n",
    "for utterance in all_utterances:\n",
    "    actions = [action for action, data in utterance['predictions'].items() \n",
    "              if data.get('is_active', False)]\n",
    "    \n",
    "    if utterance['speaker'] == 'therapist':\n",
    "        therapist_actions.update(actions)\n",
    "    else:\n",
    "        client_actions.update(actions)\n",
    "\n",
    "# Top actions\n",
    "print(\"\\nTop 15 Therapist Actions:\")\n",
    "for action, count in therapist_actions.most_common(15):\n",
    "    bar = \"‚ñà\" * int(count / 10)\n",
    "    print(f\"   {action:30s} {count:4d} {bar}\")\n",
    "\n",
    "print(\"\\nTop 15 Client Actions:\")\n",
    "for action, count in client_actions.most_common(15):\n",
    "    bar = \"‚ñà\" * int(count / 10)\n",
    "    print(f\"   {action:30s} {count:4d} {bar}\")\n",
    "\n",
    "# Unique actions\n",
    "therapist_only = set(therapist_actions.keys()) - set(client_actions.keys())\n",
    "client_only = set(client_actions.keys()) - set(therapist_actions.keys())\n",
    "\n",
    "if therapist_only:\n",
    "    print(\"\\nActions unique to therapist:\")\n",
    "    for action in sorted(therapist_only):\n",
    "        print(f\"   ‚Ä¢ {action}\")\n",
    "\n",
    "if client_only:\n",
    "    print(\"\\nActions unique to client:\")\n",
    "    for action in sorted(client_only):\n",
    "        print(f\"   ‚Ä¢ {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ Export Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary\n",
    "summary = {\n",
    "    'transcripts_analyzed': len(annotated_transcripts),\n",
    "    'total_utterances': len(all_utterances),\n",
    "    'therapist_utterances': sum(1 for u in all_utterances if u['speaker'] == 'therapist'),\n",
    "    'client_utterances': sum(1 for u in all_utterances if u['speaker'] == 'client'),\n",
    "    'therapist_network': {\n",
    "        'nodes': G_therapist_combined.number_of_nodes(),\n",
    "        'edges': G_therapist_combined.number_of_edges(),\n",
    "        'density': float(nx.density(G_therapist_combined)),\n",
    "        'top_actions': [action for action, _ in therapist_actions.most_common(20)]\n",
    "    },\n",
    "    'client_network': {\n",
    "        'nodes': G_client_combined.number_of_nodes(),\n",
    "        'edges': G_client_combined.number_of_edges(),\n",
    "        'density': float(nx.density(G_client_combined)),\n",
    "        'top_actions': [action for action, _ in client_actions.most_common(20)]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(output_dir / 'analysis_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìÅ Output directory: {output_dir}\")\n",
    "print(f\"\\nüìä Files generated:\")\n",
    "print(f\"   ‚Ä¢ annotated_transcripts.json\")\n",
    "print(f\"   ‚Ä¢ analysis_summary.json\")\n",
    "print(f\"   ‚Ä¢ combined_therapist_network.png\")\n",
    "print(f\"   ‚Ä¢ combined_client_network.png\")\n",
    "print(f\"   ‚Ä¢ networks/transcript_*_therapist.png (per transcript)\")\n",
    "print(f\"   ‚Ä¢ networks/transcript_*_client.png (per transcript)\")\n",
    "print(\"\\n‚úÖ All done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}