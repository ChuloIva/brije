{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Training Data Generator\n",
    "\n",
    "Generate balanced sentiment examples for binary sentiment probes:\n",
    "- **Positive sentiment**: 700 examples\n",
    "- **Negative sentiment**: 700 examples\n",
    "\n",
    "## Sentiment Categories\n",
    "\n",
    "**Positive**: joy, gratitude, hope, excitement, love, pride, contentment, inspiration, relief, satisfaction\n",
    "\n",
    "**Negative**: sadness, anger, fear, disgust, shame, anxiety, frustration, disappointment, guilt, loneliness\n",
    "\n",
    "## Requirements\n",
    "- Ollama running locally with Gemma 3 4B\n",
    "- Python 3.8+\n",
    "- Rich variation in contexts and language styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from typing import List, Dict\n",
    "from dataclasses import dataclass, asdict\n",
    "from tqdm.notebook import tqdm\n",
    "import nest_asyncio\n",
    "\n",
    "# Allow nested event loops (required for Jupyter)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"✅ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Sentiment Categories and Variation Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment definitions\n",
    "SENTIMENTS = {\n",
    "    \"positive\": {\n",
    "        \"label\": \"positive\",\n",
    "        \"emotions\": [\n",
    "            \"joy\", \"gratitude\", \"hope\", \"excitement\", \"love\", \n",
    "            \"pride\", \"contentment\", \"inspiration\", \"relief\", \"satisfaction\"\n",
    "        ],\n",
    "        \"description\": \"expressing positive emotions, uplifting thoughts, or optimistic perspectives\"\n",
    "    },\n",
    "    \"negative\": {\n",
    "        \"label\": \"negative\",\n",
    "        \"emotions\": [\n",
    "            \"sadness\", \"anger\", \"fear\", \"disgust\", \"shame\",\n",
    "            \"anxiety\", \"frustration\", \"disappointment\", \"guilt\", \"loneliness\"\n",
    "        ],\n",
    "        \"description\": \"expressing negative emotions, pessimistic thoughts, or distressing perspectives\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Domains where sentiment is expressed\n",
    "DOMAINS = [\n",
    "    \"personal relationships\", \"romantic relationships\", \"family dynamics\",\n",
    "    \"friendships\", \"career and work\", \"professional achievements\",\n",
    "    \"creative pursuits\", \"academic learning\", \"health and wellness\",\n",
    "    \"financial situations\", \"daily life experiences\", \"personal growth\",\n",
    "    \"social interactions\", \"life transitions\", \"hobbies and interests\",\n",
    "    \"community involvement\", \"parenting\", \"retirement\", \"travel experiences\",\n",
    "    \"achievements and goals\", \"challenges and setbacks\"\n",
    "]\n",
    "\n",
    "# Language styles\n",
    "LANGUAGE_STYLES = [\n",
    "    \"casual and conversational\",\n",
    "    \"introspective and reflective\",\n",
    "    \"straightforward and direct\",\n",
    "    \"expressive and emotional\",\n",
    "    \"minimalist and concise\",\n",
    "    \"detailed and descriptive\",\n",
    "    \"poetic and metaphorical\",\n",
    "    \"analytical and thoughtful\"\n",
    "]\n",
    "\n",
    "# Triggers/situations\n",
    "TRIGGERS = [\n",
    "    \"receiving news\", \"having a conversation\", \"completing a task\",\n",
    "    \"experiencing a setback\", \"achieving a goal\", \"spending time with someone\",\n",
    "    \"reflecting on the day\", \"making a discovery\", \"facing a challenge\",\n",
    "    \"receiving feedback\", \"observing something\", \"making a decision\",\n",
    "    \"experiencing change\", \"remembering the past\", \"anticipating the future\",\n",
    "    \"helping someone\", \"being helped\", \"learning something new\",\n",
    "    \"overcoming an obstacle\", \"dealing with loss\"\n",
    "]\n",
    "\n",
    "print(f\"Positive emotions: {', '.join(SENTIMENTS['positive']['emotions'])}\")\n",
    "print(f\"Negative emotions: {', '.join(SENTIMENTS['negative']['emotions'])}\")\n",
    "print(f\"Domains: {len(DOMAINS)}\")\n",
    "print(f\"Language styles: {len(LANGUAGE_STYLES)}\")\n",
    "print(f\"Triggers: {len(TRIGGERS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SentimentExample:\n",
    "    text: str\n",
    "    sentiment: str  # \"positive\" or \"negative\"\n",
    "    emotion: str\n",
    "    domain: str\n",
    "    trigger: str\n",
    "    language_style: str\n",
    "\n",
    "\n",
    "class SentimentDataGenerator:\n",
    "    def __init__(self, base_url=\"http://localhost:11434\", max_parallel=4):\n",
    "        self.base_url = base_url\n",
    "        self.max_parallel = max_parallel\n",
    "    \n",
    "    def create_prompt(self, sentiment: str, emotion: str, domain: str, \n",
    "                     trigger: str, language_style: str) -> str:\n",
    "        \"\"\"Create prompt for generating sentiment example\"\"\"\n",
    "        sentiment_desc = SENTIMENTS[sentiment][\"description\"]\n",
    "        \n",
    "        return f\"\"\"Generate a brief first-person example of someone {sentiment_desc}.\n",
    "\n",
    "Sentiment: {sentiment}\n",
    "Specific emotion: {emotion}\n",
    "Context: {domain}\n",
    "Situation: {trigger}\n",
    "Style: {language_style}\n",
    "\n",
    "Requirements:\n",
    "- Write in first person (I, my, me)\n",
    "- 2-4 sentences maximum\n",
    "- Clearly express {sentiment} sentiment through {emotion}\n",
    "- Use {language_style} writing style\n",
    "- Make it authentic and natural\n",
    "- Focus on {domain}\n",
    "- Show genuine emotion, not just state it\n",
    "\n",
    "Example only (no explanation):\"\"\"\n",
    "    \n",
    "    async def generate_one(self, session: aiohttp.ClientSession, \n",
    "                          semaphore: asyncio.Semaphore,\n",
    "                          sentiment: str, emotion: str, domain: str,\n",
    "                          trigger: str, language_style: str,\n",
    "                          model: str) -> SentimentExample:\n",
    "        \"\"\"Generate one sentiment example\"\"\"\n",
    "        async with semaphore:\n",
    "            prompt = self.create_prompt(sentiment, emotion, domain, trigger, language_style)\n",
    "            \n",
    "            try:\n",
    "                async with session.post(\n",
    "                    f\"{self.base_url}/api/generate\",\n",
    "                    json={\"model\": model, \"prompt\": prompt, \"stream\": False},\n",
    "                    timeout=aiohttp.ClientTimeout(total=60)\n",
    "                ) as response:\n",
    "                    result = await response.json()\n",
    "                    text = result.get('response', '').strip()\n",
    "                    \n",
    "                    # Clean up\n",
    "                    text = text.replace('\"', '').strip()\n",
    "                    if not text or len(text) < 20:\n",
    "                        return None\n",
    "                    \n",
    "                    return SentimentExample(\n",
    "                        text=text,\n",
    "                        sentiment=sentiment,\n",
    "                        emotion=emotion,\n",
    "                        domain=domain,\n",
    "                        trigger=trigger,\n",
    "                        language_style=language_style\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError: {e}\")\n",
    "                return None\n",
    "    \n",
    "    async def generate_batch_async(self, count: int, sentiment: str, \n",
    "                                  model: str, pbar=None) -> List[SentimentExample]:\n",
    "        \"\"\"Generate batch of examples for one sentiment\"\"\"\n",
    "        semaphore = asyncio.Semaphore(self.max_parallel)\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = []\n",
    "            emotions = SENTIMENTS[sentiment][\"emotions\"]\n",
    "            \n",
    "            for _ in range(count):\n",
    "                emotion = random.choice(emotions)\n",
    "                domain = random.choice(DOMAINS)\n",
    "                trigger = random.choice(TRIGGERS)\n",
    "                language_style = random.choice(LANGUAGE_STYLES)\n",
    "                \n",
    "                task = self.generate_one(\n",
    "                    session, semaphore, sentiment, emotion,\n",
    "                    domain, trigger, language_style, model\n",
    "                )\n",
    "                tasks.append(task)\n",
    "            \n",
    "            results = await asyncio.gather(*tasks)\n",
    "            valid_results = [r for r in results if r is not None]\n",
    "            \n",
    "            if pbar:\n",
    "                pbar.update(len(valid_results))\n",
    "            \n",
    "            return valid_results\n",
    "    \n",
    "    def generate_sentiment_dataset(self, examples_per_sentiment: int,\n",
    "                                  model: str = \"gemma3:4b\") -> Dict[str, List[SentimentExample]]:\n",
    "        \"\"\"Generate complete balanced sentiment dataset\"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"SENTIMENT DATA GENERATION\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Examples per sentiment: {examples_per_sentiment}\")\n",
    "        print(f\"Total examples: {examples_per_sentiment * 2}\")\n",
    "        print(f\"Model: {model}\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        results = {\"positive\": [], \"negative\": []}\n",
    "        batch_size = 50  # Generate in batches\n",
    "        \n",
    "        for sentiment in [\"positive\", \"negative\"]:\n",
    "            print(f\"\\nGenerating {sentiment} examples...\")\n",
    "            num_batches = (examples_per_sentiment + batch_size - 1) // batch_size\n",
    "            \n",
    "            with tqdm(total=examples_per_sentiment, desc=sentiment.capitalize()) as pbar:\n",
    "                for batch_idx in range(num_batches):\n",
    "                    batch_count = min(batch_size, examples_per_sentiment - batch_idx * batch_size)\n",
    "                    \n",
    "                    batch_examples = asyncio.run(\n",
    "                        self.generate_batch_async(batch_count, sentiment, model, pbar)\n",
    "                    )\n",
    "                    results[sentiment].extend(batch_examples)\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"✅ Generator class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'examples_per_sentiment': 700,\n",
    "    'model': 'gemma3:4b',\n",
    "    'parallel_requests': 8,\n",
    "    'output_dir': './generated_data',\n",
    "    'base_url': 'http://localhost:11434'\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Ollama Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{CONFIG['base_url']}/api/tags\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"✅ Ollama is running\")\n",
    "        models = response.json().get('models', [])\n",
    "        print(f\"Available models: {[m['name'] for m in models][:5]}\")\n",
    "    else:\n",
    "        print(\"❌ Ollama not responding correctly\")\nexcept Exception as e:\n",
    "    print(f\"❌ Cannot connect to Ollama: {e}\")\n",
    "    print(\"\\nMake sure Ollama is running with: ollama serve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator\n",
    "generator = SentimentDataGenerator(\n",
    "    base_url=CONFIG['base_url'],\n",
    "    max_parallel=CONFIG['parallel_requests']\n",
    ")\n",
    "\n",
    "# Generate data\n",
    "start_time = time.time()\n",
    "\n",
    "sentiment_data = generator.generate_sentiment_dataset(\n",
    "    examples_per_sentiment=CONFIG['examples_per_sentiment'],\n",
    "    model=CONFIG['model']\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n\\n{'='*70}\")\n",
    "print(\"GENERATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Positive examples: {len(sentiment_data['positive'])}\")\n",
    "print(f\"Negative examples: {len(sentiment_data['negative'])}\")\n",
    "print(f\"Total: {len(sentiment_data['positive']) + len(sentiment_data['negative'])}\")\n",
    "print(f\"Time: {elapsed/60:.1f} minutes\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to JSONL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "\n",
    "# Save each sentiment to separate file\n",
    "for sentiment in ['positive', 'negative']:\n",
    "    filename = f\"{CONFIG['output_dir']}/{sentiment}_sentiment_{len(sentiment_data[sentiment])}.jsonl\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        for example in sentiment_data[sentiment]:\n",
    "            f.write(json.dumps(asdict(example)) + '\\n')\n",
    "    \n",
    "    print(f\"✅ Saved {len(sentiment_data[sentiment])} {sentiment} examples to {filename}\")\n",
    "\n",
    "# Also save combined file\n",
    "combined_filename = f\"{CONFIG['output_dir']}/sentiment_combined_{CONFIG['examples_per_sentiment']*2}.jsonl\"\n",
    "with open(combined_filename, 'w') as f:\n",
    "    for sentiment in ['positive', 'negative']:\n",
    "        for example in sentiment_data[sentiment]:\n",
    "            f.write(json.dumps(asdict(example)) + '\\n')\n",
    "\n",
    "print(f\"\\n✅ Saved combined dataset to {combined_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA QUALITY VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for sentiment in ['positive', 'negative']:\n",
    "    examples = sentiment_data[sentiment]\n",
    "    \n",
    "    print(f\"\\n{sentiment.upper()} SENTIMENT ({len(examples)} examples)\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Emotion distribution\n",
    "    emotions = Counter(ex.emotion for ex in examples)\n",
    "    print(\"\\nEmotion distribution:\")\n",
    "    for emotion, count in emotions.most_common():\n",
    "        print(f\"  {emotion:20s}: {count:3d} ({count/len(examples)*100:.1f}%)\")\n",
    "    \n",
    "    # Text length stats\n",
    "    lengths = [len(ex.text) for ex in examples]\n",
    "    print(f\"\\nText length: min={min(lengths)}, max={max(lengths)}, avg={sum(lengths)/len(lengths):.0f}\")\n",
    "    \n",
    "    # Sample examples\n",
    "    print(\"\\nSample examples:\")\n",
    "    for i, ex in enumerate(random.sample(examples, min(3, len(examples))), 1):\n",
    "        print(f\"\\n  {i}. [{ex.emotion}] {ex.text[:150]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ Generated balanced sentiment dataset ready for probe training!\n",
    "\n",
    "**Output files:**\n",
    "- `positive_sentiment_700.jsonl`\n",
    "- `negative_sentiment_700.jsonl`\n",
    "- `sentiment_combined_1400.jsonl`\n",
    "\n",
    "**Next steps:**\n",
    "1. Use these files for activation capture\n",
    "2. Train binary sentiment probes\n",
    "3. Integrate with existing probe inference system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
