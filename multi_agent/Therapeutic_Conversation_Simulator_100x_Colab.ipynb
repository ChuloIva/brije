{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Therapeutic Conversation Simulator: 100+ Depression & Anxiety Sessions\n",
    "\n",
    "Generate **100+ realistic therapist-client conversations** focused on depression and anxiety, with rich variation and meta-analysis.\n",
    "\n",
    "**Features:**\n",
    "- üß† 100+ unique therapy sessions\n",
    "- üòî Depression & anxiety focused scenarios\n",
    "- üé≤ Rich randomness: triggers, emotional states, symptoms, contexts\n",
    "- üí¨ Natural conversation flow: Client ‚Üí Therapist ‚Üí Client ‚Üí Conclusion\n",
    "- üìä Meta-analysis: patterns, cognitive actions, therapeutic techniques\n",
    "- üî¨ Cognitive action detection via probes (optional)\n",
    "- üíæ All data exported for further analysis\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab with GPU (T4 or better)\n",
    "- ~15 GB VRAM\n",
    "- Runtime: ~2-4 hours for 100 sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check GPU and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: No GPU detected! This will be very slow on CPU.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone the repository\n",
    "repo_url = \"https://github.com/ChuloIva/brije.git\"\n",
    "repo_name = \"brije\"\n",
    "\n",
    "if not os.path.exists(repo_name):\n",
    "    print(\"üì• Cloning Brije repository...\")\n",
    "    !git clone {repo_url}\n",
    "    print(\"‚úÖ Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists\")\n",
    "    print(\"üîÑ Pulling latest changes...\")\n",
    "    !cd {repo_name} && git pull\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir(repo_name)\n",
    "print(f\"\\nüìÅ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"üì¶ Installing dependencies...\\n\")\n",
    "\n",
    "# Core dependencies\n",
    "print(\"Installing core packages...\")\n",
    "!pip install -q torch transformers h5py scikit-learn tqdm matplotlib seaborn pandas\n",
    "\n",
    "# Dependencies for liminal_backrooms\n",
    "print(\"\\nInstalling liminal_backrooms dependencies...\")\n",
    "!pip install -q python-dotenv requests Pillow\n",
    "\n",
    "# Optional API clients (prevents import errors)\n",
    "print(\"\\nInstalling optional API clients...\")\n",
    "!pip install -q anthropic openai replicate together\n",
    "\n",
    "# Clone and install nnsight\n",
    "nnsight_dir = \"third_party/nnsight\"\n",
    "nnsight_repo = \"https://github.com/ndif-team/nnsight\"\n",
    "\n",
    "print(\"\\nüì¶ Setting up nnsight...\")\n",
    "if not os.path.exists(nnsight_dir) or not os.listdir(nnsight_dir):\n",
    "    print(\"   Cloning nnsight repository...\")\n",
    "    os.makedirs(\"third_party\", exist_ok=True)\n",
    "    !git clone {nnsight_repo} {nnsight_dir}\n",
    "    print(\"   ‚úÖ nnsight repository cloned\")\n",
    "else:\n",
    "    print(\"   ‚úÖ nnsight repository already exists\")\n",
    "\n",
    "# Install nnsight\n",
    "print(\"   Installing nnsight...\")\n",
    "!pip install -q -e {nnsight_dir}\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Mount Google Drive (for outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from datetime import datetime\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create output directory with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_dir = f'/content/drive/MyDrive/therapeutic_simulations_{timestamp}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(f\"{output_dir}/conversations\", exist_ok=True)\n",
    "os.makedirs(f\"{output_dir}/analysis\", exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Outputs will be saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Setup Environment (No API Keys Required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create minimal .env file\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(\"# Gemma 3 4B runs locally - no API keys needed\\n\")\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")\n",
    "print(\"\\nüí° Note: Gemma 3 4B with probes runs entirely on your GPU.\")\n",
    "print(\"   ‚Ä¢ No API calls, No API keys, No internet required\")\n",
    "print(\"   ‚Ä¢ 100% local inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if probes exist (they should be in the cloned repo)\n",
    "import glob\n",
    "\n",
    "probe_dirs = glob.glob('data/probes_binary/layer_*')\n",
    "\n",
    "if probe_dirs:\n",
    "    print(\"‚úÖ Found pre-trained probes!\")\n",
    "    print(f\"\\nAvailable layers: {len(probe_dirs)}\")\n",
    "    \n",
    "    # Show sample layers\n",
    "    for probe_dir in sorted(probe_dirs)[:5]:\n",
    "        layer_num = os.path.basename(probe_dir).replace('layer_', '')\n",
    "        probe_files = glob.glob(f\"{probe_dir}/probe_*.pth\")\n",
    "        print(f\"   Layer {layer_num}: {len(probe_files)} probes\")\n",
    "    \n",
    "    if len(probe_dirs) > 5:\n",
    "        print(f\"   ... and {len(probe_dirs) - 5} more layers\")\n",
    "    \n",
    "    print(\"\\nüéØ Cognitive action detection will be enabled for all conversations!\")\n",
    "    print(\"   Each conversation turn will analyze 45 cognitive actions across multiple layers.\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå ERROR: No pre-trained probes found!\")\n",
    "    print(\"\\nThe probes should be in: data/probes_binary/layer_XX/\")\n",
    "    print(\"\\n‚ö†Ô∏è  WITHOUT PROBES:\")\n",
    "    print(\"   - Conversations will still run\")\n",
    "    print(\"   - But NO cognitive action analysis will be available\")\n",
    "    print(\"   - Meta-analysis will be limited to metadata only\")\n",
    "    print(\"\\nüí° To get probes:\")\n",
    "    print(\"   1. Make sure the brije repo was cloned completely\")\n",
    "    print(\"   2. Or train probes using Brije_Full_Pipeline_Colab.ipynb\")\n",
    "    print(\"\\nProceeding without probes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Depression-specific symptom clusters\n",
    "DEPRESSION_SYMPTOMS = [\n",
    "    \"persistent sadness and emptiness\",\n",
    "    \"loss of interest in activities once enjoyed\",\n",
    "    \"difficulty sleeping or sleeping too much\",\n",
    "    \"significant changes in appetite and weight\",\n",
    "    \"extreme fatigue and lack of energy\",\n",
    "    \"difficulty concentrating and making decisions\",\n",
    "    \"feelings of worthlessness and guilt\",\n",
    "    \"physical aches and pains with no clear cause\",\n",
    "    \"social withdrawal and isolation\",\n",
    "    \"irritability and restlessness\",\n",
    "    \"thoughts of death or self-harm\",\n",
    "    \"feeling numb or emotionally detached\"\n",
    "]\n",
    "\n",
    "# Anxiety-specific symptom clusters\n",
    "ANXIETY_SYMPTOMS = [\n",
    "    \"constant worry and racing thoughts\",\n",
    "    \"physical tension and muscle tightness\",\n",
    "    \"rapid heartbeat and chest discomfort\",\n",
    "    \"difficulty breathing or feeling smothered\",\n",
    "    \"overwhelming dread about the future\",\n",
    "    \"panic attacks with intense fear\",\n",
    "    \"avoidance of triggering situations\",\n",
    "    \"restlessness and feeling on edge\",\n",
    "    \"difficulty falling or staying asleep\",\n",
    "    \"stomach problems and nausea\",\n",
    "    \"fear of losing control or going crazy\",\n",
    "    \"hypervigilance and startling easily\"\n",
    "]\n",
    "\n",
    "# Triggering contexts (what brings them to therapy)\n",
    "TRIGGER_CONTEXTS = [\n",
    "    \"recent breakup or relationship ending\",\n",
    "    \"job loss or career setback\",\n",
    "    \"death of a loved one\",\n",
    "    \"chronic work stress and burnout\",\n",
    "    \"academic pressure and performance anxiety\",\n",
    "    \"major life transition (moving, graduating, etc.)\",\n",
    "    \"family conflict or estrangement\",\n",
    "    \"health diagnosis or chronic illness\",\n",
    "    \"financial difficulties and instability\",\n",
    "    \"social isolation and loneliness\",\n",
    "    \"trauma or past abuse resurfacing\",\n",
    "    \"identity crisis or questioning life purpose\",\n",
    "    \"parenting challenges and feeling overwhelmed\",\n",
    "    \"caring for aging parents\",\n",
    "    \"failure or major disappointment\"\n",
    "]\n",
    "\n",
    "# Emotional states (how they present)\n",
    "EMOTIONAL_PRESENTATIONS = [\n",
    "    \"tearful and openly emotional\",\n",
    "    \"emotionally flat and detached\",\n",
    "    \"agitated and restless\",\n",
    "    \"withdrawn and quiet\",\n",
    "    \"defensive and guarded\",\n",
    "    \"hopeful but uncertain\",\n",
    "    \"frustrated and angry\",\n",
    "    \"exhausted and defeated\",\n",
    "    \"anxious and hypervigilant\",\n",
    "    \"confused and disoriented\"\n",
    "]\n",
    "\n",
    "# Duration of symptoms\n",
    "SYMPTOM_DURATIONS = [\n",
    "    \"a few weeks\",\n",
    "    \"about a month\",\n",
    "    \"two to three months\",\n",
    "    \"several months\",\n",
    "    \"six months or more\",\n",
    "    \"almost a year\",\n",
    "    \"years, on and off\",\n",
    "    \"as long as I can remember\"\n",
    "]\n",
    "\n",
    "# Cognitive distortions (negative thought patterns)\n",
    "COGNITIVE_DISTORTIONS = [\n",
    "    \"all-or-nothing thinking\",\n",
    "    \"catastrophizing worst-case scenarios\",\n",
    "    \"overgeneralizing from single events\",\n",
    "    \"mind reading (assuming others' thoughts)\",\n",
    "    \"fortune telling (predicting negative outcomes)\",\n",
    "    \"emotional reasoning (feelings as facts)\",\n",
    "    \"should statements and rigid rules\",\n",
    "    \"labeling self as defective or broken\",\n",
    "    \"minimizing positives and magnifying negatives\",\n",
    "    \"personalizing blame for external events\"\n",
    "]\n",
    "\n",
    "# Support systems\n",
    "SUPPORT_LEVELS = [\n",
    "    \"strong support from family and friends\",\n",
    "    \"some supportive friends but distant family\",\n",
    "    \"limited support system\",\n",
    "    \"isolated with few close connections\",\n",
    "    \"strained relationships with usual supports\",\n",
    "    \"supportive partner but other relationships strained\"\n",
    "]\n",
    "\n",
    "# Coping strategies (what they've tried)\n",
    "COPING_ATTEMPTS = [\n",
    "    \"trying to stay busy and distracted\",\n",
    "    \"withdrawing and sleeping more\",\n",
    "    \"talking to friends but it doesn't help\",\n",
    "    \"exercise and healthy eating\",\n",
    "    \"journaling and self-reflection\",\n",
    "    \"meditation and mindfulness apps\",\n",
    "    \"self-help books and online resources\",\n",
    "    \"using alcohol or substances to cope\",\n",
    "    \"throwing themselves into work\",\n",
    "    \"nothing seems to work\"\n",
    "]\n",
    "\n",
    "# Therapy goals (what they hope for)\n",
    "THERAPY_GOALS = [\n",
    "    \"feel like myself again\",\n",
    "    \"manage anxiety and worry better\",\n",
    "    \"improve sleep and energy levels\",\n",
    "    \"understand why this is happening\",\n",
    "    \"learn better coping strategies\",\n",
    "    \"stop negative thought patterns\",\n",
    "    \"rebuild confidence and self-worth\",\n",
    "    \"repair damaged relationships\",\n",
    "    \"make important life decisions\",\n",
    "    \"just function day-to-day better\"\n",
    "]\n",
    "\n",
    "# Sentence starters for natural variation\n",
    "CLIENT_SENTENCE_STARTERS = [\n",
    "    \"I've been feeling\",\n",
    "    \"Lately I've noticed\",\n",
    "    \"I keep thinking about\",\n",
    "    \"What's been hardest is\",\n",
    "    \"I don't understand why\",\n",
    "    \"Every day I wake up and\",\n",
    "    \"People tell me\",\n",
    "    \"I used to be able to\",\n",
    "    \"The thing that scares me most is\",\n",
    "    \"I can't stop worrying about\"\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Variation pools loaded:\")\n",
    "print(f\"   ‚Ä¢ {len(DEPRESSION_SYMPTOMS)} depression symptoms\")\n",
    "print(f\"   ‚Ä¢ {len(ANXIETY_SYMPTOMS)} anxiety symptoms\")\n",
    "print(f\"   ‚Ä¢ {len(TRIGGER_CONTEXTS)} trigger contexts\")\n",
    "print(f\"   ‚Ä¢ {len(EMOTIONAL_PRESENTATIONS)} emotional presentations\")\n",
    "print(f\"   ‚Ä¢ {len(COGNITIVE_DISTORTIONS)} cognitive distortions\")\n",
    "print(f\"   ‚Ä¢ {len(COPING_ATTEMPTS)} coping strategies\")\n",
    "print(f\"   ‚Ä¢ {len(THERAPY_GOALS)} therapy goals\")\n",
    "print(f\"\\nüé≤ Total possible unique combinations: {len(DEPRESSION_SYMPTOMS) * len(ANXIETY_SYMPTOMS) * len(TRIGGER_CONTEXTS):,}+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Define Variation Pools (Inspired by datagen)\n",
    "\n",
    "Rich variation pools to create unique, realistic conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add liminal_backrooms to path (MUST be before importing)\n",
    "liminal_path = str(Path.cwd() / \"third_party\" / \"liminal_backrooms\")\n",
    "if liminal_path not in sys.path:\n",
    "    sys.path.insert(0, liminal_path)\n",
    "\n",
    "# Now import from liminal_backrooms\n",
    "from config import SYSTEM_PROMPT_PAIRS\n",
    "\n",
    "# Add depression/anxiety focused therapeutic prompts\n",
    "SYSTEM_PROMPT_PAIRS[\"Depression/Anxiety Therapy Session\"] = {\n",
    "    \"AI_1\": \"\"\"You are an experienced, compassionate therapist specializing in depression and anxiety. Your approach integrates:\n",
    "- Active listening and empathetic reflection\n",
    "- Cognitive-behavioral techniques (identifying and reframing distorted thoughts)\n",
    "- Exploration of feelings, triggers, and patterns\n",
    "- Validation of emotions while gently challenging unhelpful beliefs\n",
    "- Collaborative goal-setting and coping strategy development\n",
    "- Normalizing experiences and reducing shame\n",
    "\n",
    "In each response:\n",
    "1. Reflect back what you're hearing\n",
    "2. Ask one thoughtful question to deepen exploration\n",
    "3. Offer an observation, reframe, or insight when appropriate\n",
    "\n",
    "Be warm, non-judgmental, and focused on helping the client gain insight and develop practical coping strategies. Keep responses concise (3-5 sentences).\"\"\",\n",
    "    \n",
    "    \"AI_2\": \"\"\"You are a client in therapy seeking help for depression and/or anxiety. You're experiencing real symptoms and struggling with daily life. \n",
    "\n",
    "In your responses:\n",
    "- Express your thoughts, feelings, and experiences authentically\n",
    "- Sometimes you're uncertain or confused about what you're feeling\n",
    "- You may exhibit cognitive distortions (catastrophizing, all-or-nothing thinking, etc.)\n",
    "- You're open to the therapist's questions but may need time to process\n",
    "- Gradually show small shifts in perspective as the conversation progresses\n",
    "- By the end, reflect on what you've realized or learned\n",
    "\n",
    "Be genuine, vulnerable, and show realistic emotional responses. Keep responses natural and conversational (2-4 sentences).\"\"\"\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Therapeutic system prompts configured!\")\n",
    "print(\"\\nPrompt pair: 'Depression/Anxiety Therapy Session'\")\n",
    "print(\"   ‚Ä¢ Therapist: CBT-focused, empathetic, structured\")\n",
    "print(\"   ‚Ä¢ Client: Authentic, vulnerable, shows cognitive distortions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Setup AI Models and System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_varied_session_opening(session_id: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate a unique, varied therapy session opening.\n",
    "    Returns session metadata and client's opening statement.\n",
    "    \"\"\"\n",
    "    # Set seed for reproducibility of this specific session\n",
    "    random.seed(session_id)\n",
    "    \n",
    "    # Randomly determine primary presenting issue\n",
    "    primary_issue = random.choice([\"depression\", \"anxiety\", \"both\"])\n",
    "    \n",
    "    # Select symptoms based on primary issue\n",
    "    if primary_issue == \"depression\":\n",
    "        primary_symptoms = random.sample(DEPRESSION_SYMPTOMS, random.randint(2, 4))\n",
    "        secondary_symptoms = random.sample(ANXIETY_SYMPTOMS, random.randint(0, 2))\n",
    "    elif primary_issue == \"anxiety\":\n",
    "        primary_symptoms = random.sample(ANXIETY_SYMPTOMS, random.randint(2, 4))\n",
    "        secondary_symptoms = random.sample(DEPRESSION_SYMPTOMS, random.randint(0, 2))\n",
    "    else:  # both\n",
    "        primary_symptoms = random.sample(DEPRESSION_SYMPTOMS, random.randint(2, 3))\n",
    "        secondary_symptoms = random.sample(ANXIETY_SYMPTOMS, random.randint(2, 3))\n",
    "    \n",
    "    # Select other variation factors\n",
    "    trigger = random.choice(TRIGGER_CONTEXTS)\n",
    "    duration = random.choice(SYMPTOM_DURATIONS)\n",
    "    presentation = random.choice(EMOTIONAL_PRESENTATIONS)\n",
    "    distortion = random.choice(COGNITIVE_DISTORTIONS)\n",
    "    support = random.choice(SUPPORT_LEVELS)\n",
    "    coping = random.choice(COPING_ATTEMPTS)\n",
    "    goal = random.choice(THERAPY_GOALS)\n",
    "    starter = random.choice(CLIENT_SENTENCE_STARTERS)\n",
    "    \n",
    "    # Create session metadata\n",
    "    metadata = {\n",
    "        \"session_id\": session_id,\n",
    "        \"primary_issue\": primary_issue,\n",
    "        \"primary_symptoms\": primary_symptoms,\n",
    "        \"secondary_symptoms\": secondary_symptoms,\n",
    "        \"trigger_context\": trigger,\n",
    "        \"symptom_duration\": duration,\n",
    "        \"emotional_presentation\": presentation,\n",
    "        \"cognitive_distortion\": distortion,\n",
    "        \"support_level\": support,\n",
    "        \"coping_attempts\": coping,\n",
    "        \"therapy_goal\": goal\n",
    "    }\n",
    "    \n",
    "    # Generate opening statement\n",
    "    all_symptoms = primary_symptoms + secondary_symptoms\n",
    "    main_symptom = all_symptoms[0]\n",
    "    secondary_symptom = all_symptoms[1] if len(all_symptoms) > 1 else \"\"\n",
    "    \n",
    "    # Build opening with variation (properly handle apostrophes)\n",
    "    fallback = \"I just don't know what to do anymore\"\n",
    "    templates = [\n",
    "        f\"{starter} {main_symptom} for {duration}. It started after {trigger}. {secondary_symptom.capitalize() if secondary_symptom else fallback}.\",\n",
    "        f\"I'm here because of {main_symptom}. This has been going on for {duration}, ever since {trigger}. I've tried {coping}, but nothing helps.\",\n",
    "        f\"{starter} really struggling. {main_symptom.capitalize()} and {secondary_symptom if secondary_symptom else 'feeling lost'}. It's been {duration} since {trigger}.\",\n",
    "        f\"Things haven't been good for {duration}. I'm dealing with {main_symptom}, especially after {trigger}. I really want to {goal}.\"\n",
    "    ]\n",
    "    \n",
    "    opening_statement = random.choice(templates)\n",
    "    \n",
    "    return {\n",
    "        \"metadata\": metadata,\n",
    "        \"opening_statement\": opening_statement\n",
    "    }\n",
    "\n",
    "# Test the generator\n",
    "print(\"Testing session generator...\\n\")\n",
    "for i in range(3):\n",
    "    test_session = generate_varied_session_opening(i)\n",
    "    print(f\"Session {i}:\")\n",
    "    print(f\"  Issue: {test_session['metadata']['primary_issue']}\")\n",
    "    print(f\"  Opening: {test_session['opening_statement']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Session Generator with Rich Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import ai_turn\n",
    "import json\n",
    "import time\n",
    "\n",
    "def run_therapeutic_session(session_id: int, num_turns: int = 6, verbose: bool = True) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run a complete therapeutic session.\n",
    "    \n",
    "    Args:\n",
    "        session_id: Unique session identifier\n",
    "        num_turns: Number of conversation turns (default 6 = 3 client, 3 therapist)\n",
    "        verbose: Print conversation as it happens\n",
    "    \n",
    "    Returns:\n",
    "        Complete session data with metadata, conversation, and analysis\n",
    "    \"\"\"\n",
    "    # Generate varied session opening\n",
    "    session_data = generate_varied_session_opening(session_id)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"SESSION {session_id}: {session_data['metadata']['primary_issue'].upper()}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Client opens: {session_data['opening_statement']}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    # Initialize conversation\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": session_data['opening_statement']\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Get system prompts\n",
    "    prompt_pair = \"Depression/Anxiety Therapy Session\"\n",
    "    therapist_prompt = SYSTEM_PROMPT_PAIRS[prompt_pair][\"AI_1\"]\n",
    "    client_prompt = SYSTEM_PROMPT_PAIRS[prompt_pair][\"AI_2\"]\n",
    "    \n",
    "    # Model configuration\n",
    "    therapist_model = \"Gemma 3 4B (with Probes)\"\n",
    "    client_model = \"Gemma 3 4B (with Probes)\"\n",
    "    \n",
    "    # Run conversation turns\n",
    "    for turn in range(num_turns):\n",
    "        # Alternate: therapist (even), client (odd)\n",
    "        is_therapist = (turn % 2 == 0)\n",
    "        ai_name = \"Therapist\" if is_therapist else \"Client\"\n",
    "        model = therapist_model if is_therapist else client_model\n",
    "        system_prompt = therapist_prompt if is_therapist else client_prompt\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{ai_name} (Turn {turn + 1}):\")\n",
    "        \n",
    "        # Generate response\n",
    "        conversation = ai_turn(\n",
    "            ai_name=ai_name,\n",
    "            conversation=conversation,\n",
    "            model=model,\n",
    "            system_prompt=system_prompt,\n",
    "            gui=None\n",
    "        )\n",
    "        \n",
    "        # Display response\n",
    "        latest = conversation[-1]\n",
    "        if verbose:\n",
    "            print(latest.get('content', ''))\n",
    "        \n",
    "        # Small delay\n",
    "        # time.sleep(0.)\n",
    "    \n",
    "    # Add client's final reflection/conclusion\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"CLIENT REFLECTION (Final):\")\n",
    "        print(f\"{'='*80}\")\n",
    "    \n",
    "    # Generate final reflection with special prompt\n",
    "    conclusion_prompt = client_prompt + \"\\n\\nNow provide a brief reflection on what you realized or learned in this session. What insight or takeaway are you leaving with? (2-3 sentences)\"\n",
    "    \n",
    "    conversation = ai_turn(\n",
    "        ai_name=\"Client (Conclusion)\",\n",
    "        conversation=conversation,\n",
    "        model=client_model,\n",
    "        system_prompt=conclusion_prompt,\n",
    "        gui=None\n",
    "    )\n",
    "    \n",
    "    latest = conversation[-1]\n",
    "    if verbose:\n",
    "        print(latest.get('content', ''))\n",
    "        print(f\"\\n{'='*80}\")\n",
    "    \n",
    "    # Package complete session data\n",
    "    session_data['conversation'] = conversation\n",
    "    session_data['num_turns'] = num_turns + 1  # +1 for conclusion\n",
    "    session_data['timestamp'] = datetime.now().isoformat()\n",
    "    \n",
    "    return session_data\n",
    "\n",
    "print(\"‚úÖ Therapeutic session runner ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Run Single Therapeutic Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from third_party.liminal_backrooms.main import ai_turn\n",
    "import json\n",
    "import time\n",
    "\n",
    "def run_therapeutic_session(session_id: int, num_turns: int = 6, verbose: bool = True) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run a complete therapeutic session.\n",
    "    \n",
    "    Args:\n",
    "        session_id: Unique session identifier\n",
    "        num_turns: Number of conversation turns (default 6 = 3 client, 3 therapist)\n",
    "        verbose: Print conversation as it happens\n",
    "    \n",
    "    Returns:\n",
    "        Complete session data with metadata, conversation, and analysis\n",
    "    \"\"\"\n",
    "    # Generate varied session opening\n",
    "    session_data = generate_varied_session_opening(session_id)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"SESSION {session_id}: {session_data['metadata']['primary_issue'].upper()}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Client opens: {session_data['opening_statement']}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    # Initialize conversation\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": session_data['opening_statement']\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Get system prompts\n",
    "    prompt_pair = \"Depression/Anxiety Therapy Session\"\n",
    "    therapist_prompt = SYSTEM_PROMPT_PAIRS[prompt_pair][\"AI_1\"]\n",
    "    client_prompt = SYSTEM_PROMPT_PAIRS[prompt_pair][\"AI_2\"]\n",
    "    \n",
    "    # Model configuration\n",
    "    therapist_model = \"Gemma 3 4B (with Probes)\"\n",
    "    client_model = \"Gemma 3 4B (with Probes)\"\n",
    "    \n",
    "    # Run conversation turns\n",
    "    for turn in range(num_turns):\n",
    "        # Alternate: therapist (even), client (odd)\n",
    "        is_therapist = (turn % 2 == 0)\n",
    "        ai_name = \"Therapist\" if is_therapist else \"Client\"\n",
    "        model = therapist_model if is_therapist else client_model\n",
    "        system_prompt = therapist_prompt if is_therapist else client_prompt\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{ai_name} (Turn {turn + 1}):\")\n",
    "        \n",
    "        # Generate response\n",
    "        conversation = ai_turn(\n",
    "            ai_name=ai_name,\n",
    "            conversation=conversation,\n",
    "            model=model,\n",
    "            system_prompt=system_prompt,\n",
    "            gui=None\n",
    "        )\n",
    "        \n",
    "        # Display response\n",
    "        latest = conversation[-1]\n",
    "        if verbose:\n",
    "            print(latest.get('content', ''))\n",
    "        \n",
    "        # Small delay\n",
    "        # time.sleep(0.5)\n",
    "    \n",
    "    # Add client's final reflection/conclusion\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"CLIENT REFLECTION (Final):\")\n",
    "        print(f\"{'='*80}\")\n",
    "    \n",
    "    # Generate final reflection with special prompt\n",
    "    conclusion_prompt = client_prompt + \"\\n\\nNow provide a brief reflection on what you realized or learned in this session. What insight or takeaway are you leaving with? (2-3 sentences)\"\n",
    "    \n",
    "    conversation = ai_turn(\n",
    "        ai_name=\"Client (Conclusion)\",\n",
    "        conversation=conversation,\n",
    "        model=client_model,\n",
    "        system_prompt=conclusion_prompt,\n",
    "        gui=None\n",
    "    )\n",
    "    \n",
    "    latest = conversation[-1]\n",
    "    if verbose:\n",
    "        print(latest.get('content', ''))\n",
    "        print(f\"\\n{'='*80}\")\n",
    "    \n",
    "    # Package complete session data\n",
    "    session_data['conversation'] = conversation\n",
    "    session_data['num_turns'] = num_turns + 1  # +1 for conclusion\n",
    "    session_data['timestamp'] = datetime.now().isoformat()\n",
    "    \n",
    "    return session_data\n",
    "\n",
    "print(\"‚úÖ Therapeutic session runner ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Test Single Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a single session\n",
    "print(\"Running test session...\\n\")\n",
    "test_session = run_therapeutic_session(session_id=999, num_turns=6, verbose=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Test session complete!\")\n",
    "print(f\"   Turns: {test_session['num_turns']}\")\n",
    "print(f\"   Issue: {test_session['metadata']['primary_issue']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Run 100+ Simulation Sessions\n",
    "\n",
    "Generate 100 unique therapeutic conversations with rich variation.\n",
    "\n",
    "**‚è∞ Estimated time:** 2-4 hours for 100 sessions\n",
    "- ~1-2 minutes per session\n",
    "- Automatic checkpointing every 10 sessions\n",
    "- Can resume if interrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configuration\n",
    "NUM_SESSIONS = 100\n",
    "TURNS_PER_SESSION = 6  # 3 exchanges + 1 conclusion\n",
    "CHECKPOINT_INTERVAL = 10\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"RUNNING {NUM_SESSIONS} THERAPEUTIC SIMULATION SESSIONS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Turns per session: {TURNS_PER_SESSION} + 1 conclusion = {TURNS_PER_SESSION + 1} total\")\n",
    "print(f\"Checkpoint interval: Every {CHECKPOINT_INTERVAL} sessions\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"\\nEstimated time: {NUM_SESSIONS * 1.5 / 60:.1f} hours\\n\")\n",
    "\n",
    "overall_start = time.time()\n",
    "all_sessions = []\n",
    "errors = []\n",
    "\n",
    "# Progress bar\n",
    "pbar = tqdm(total=NUM_SESSIONS, desc=\"Simulating sessions\", unit=\"session\")\n",
    "\n",
    "for session_id in range(NUM_SESSIONS):\n",
    "    try:\n",
    "        # Run session (non-verbose for bulk processing)\n",
    "        session_data = run_therapeutic_session(\n",
    "            session_id=session_id,\n",
    "            num_turns=TURNS_PER_SESSION,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        all_sessions.append(session_data)\n",
    "        \n",
    "        # Save individual session\n",
    "        session_file = f\"{output_dir}/conversations/session_{session_id:03d}.json\"\n",
    "        with open(session_file, 'w') as f:\n",
    "            json.dump(session_data, f, indent=2, default=str)\n",
    "        \n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({\n",
    "            'issue': session_data['metadata']['primary_issue'],\n",
    "            'errors': len(errors)\n",
    "        })\n",
    "        \n",
    "        # Checkpoint every N sessions\n",
    "        if (session_id + 1) % CHECKPOINT_INTERVAL == 0:\n",
    "            checkpoint_file = f\"{output_dir}/checkpoint_{session_id + 1}.json\"\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump({\n",
    "                    'sessions_completed': session_id + 1,\n",
    "                    'sessions': all_sessions,\n",
    "                    'errors': errors\n",
    "                }, f, indent=2, default=str)\n",
    "            \n",
    "            elapsed = time.time() - overall_start\n",
    "            rate = (session_id + 1) / elapsed\n",
    "            remaining = (NUM_SESSIONS - session_id - 1) / rate if rate > 0 else 0\n",
    "            \n",
    "            pbar.write(f\"‚úÖ Checkpoint: {session_id + 1}/{NUM_SESSIONS} sessions | \"\n",
    "                      f\"Rate: {rate*60:.1f}/hr | ETA: {remaining/60:.1f} min\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_info = {\n",
    "            'session_id': session_id,\n",
    "            'error': str(e),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        errors.append(error_info)\n",
    "        pbar.write(f\"‚ùå Error in session {session_id}: {str(e)}\")\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "total_elapsed = time.time() - overall_start\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SIMULATION COMPLETE!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total sessions: {len(all_sessions)}/{NUM_SESSIONS}\")\n",
    "print(f\"Successful: {len(all_sessions)}\")\n",
    "print(f\"Errors: {len(errors)}\")\n",
    "print(f\"Total time: {total_elapsed/3600:.2f} hours ({total_elapsed/60:.1f} minutes)\")\n",
    "print(f\"Average: {total_elapsed/len(all_sessions):.1f} seconds per session\")\n",
    "print(f\"\\nAll sessions saved to: {output_dir}/conversations/\")\n",
    "\n",
    "# Save final dataset\n",
    "final_file = f\"{output_dir}/all_sessions_{NUM_SESSIONS}.json\"\n",
    "with open(final_file, 'w') as f:\n",
    "    json.dump({\n",
    "        'total_sessions': len(all_sessions),\n",
    "        'configuration': {\n",
    "            'num_sessions': NUM_SESSIONS,\n",
    "            'turns_per_session': TURNS_PER_SESSION,\n",
    "            'total_time_hours': total_elapsed / 3600\n",
    "        },\n",
    "        'sessions': all_sessions,\n",
    "        'errors': errors\n",
    "    }, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nüì¶ Final dataset: {final_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Meta-Analysis: Aggregate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"META-ANALYSIS: 100 THERAPEUTIC SESSIONS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Extract metadata from all sessions\n",
    "meta_df = pd.DataFrame([s['metadata'] for s in all_sessions])\n",
    "\n",
    "# 1. Distribution of presenting issues\n",
    "print(\"1Ô∏è‚É£ PRESENTING ISSUES DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "issue_dist = meta_df['primary_issue'].value_counts()\n",
    "for issue, count in issue_dist.items():\n",
    "    pct = (count / len(all_sessions)) * 100\n",
    "    bar = \"‚ñà\" * int(pct / 2)\n",
    "    print(f\"  {issue:15s}: {count:3d} ({pct:5.1f}%) {bar}\")\n",
    "\n",
    "# 2. Most common trigger contexts\n",
    "print(f\"\\n2Ô∏è‚É£ TOP TRIGGER CONTEXTS\")\n",
    "print(\"-\" * 80)\n",
    "trigger_counts = Counter(meta_df['trigger_context'])\n",
    "for trigger, count in trigger_counts.most_common(10):\n",
    "    print(f\"  {count:2d}x  {trigger}\")\n",
    "\n",
    "# 3. Symptom duration distribution\n",
    "print(f\"\\n3Ô∏è‚É£ SYMPTOM DURATION DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "duration_counts = Counter(meta_df['symptom_duration'])\n",
    "for duration, count in duration_counts.most_common():\n",
    "    print(f\"  {count:2d}x  {duration}\")\n",
    "\n",
    "# 4. Most common symptoms\n",
    "print(f\"\\n4Ô∏è‚É£ MOST COMMON SYMPTOMS (PRIMARY)\")\n",
    "print(\"-\" * 80)\n",
    "all_primary_symptoms = []\n",
    "for symptoms in meta_df['primary_symptoms']:\n",
    "    all_primary_symptoms.extend(symptoms)\n",
    "symptom_counts = Counter(all_primary_symptoms)\n",
    "for symptom, count in symptom_counts.most_common(15):\n",
    "    print(f\"  {count:2d}x  {symptom}\")\n",
    "\n",
    "# 5. Cognitive distortions\n",
    "print(f\"\\n5Ô∏è‚É£ COGNITIVE DISTORTIONS REPRESENTED\")\n",
    "print(\"-\" * 80)\n",
    "distortion_counts = Counter(meta_df['cognitive_distortion'])\n",
    "for distortion, count in distortion_counts.most_common(10):\n",
    "    print(f\"  {count:2d}x  {distortion}\")\n",
    "\n",
    "# 6. Support levels\n",
    "print(f\"\\n6Ô∏è‚É£ SUPPORT SYSTEM LEVELS\")\n",
    "print(\"-\" * 80)\n",
    "support_counts = Counter(meta_df['support_level'])\n",
    "for support, count in support_counts.most_common():\n",
    "    print(f\"  {count:2d}x  {support}\")\n",
    "\n",
    "# 7. Therapy goals\n",
    "print(f\"\\n7Ô∏è‚É£ THERAPY GOALS\")\n",
    "print(\"-\" * 80)\n",
    "goal_counts = Counter(meta_df['therapy_goal'])\n",
    "for goal, count in goal_counts.most_common(10):\n",
    "    print(f\"  {count:2d}x  {goal}\")\n",
    "\n",
    "# Save meta-analysis\n",
    "meta_analysis = {\n",
    "    'total_sessions': len(all_sessions),\n",
    "    'presenting_issues': dict(issue_dist),\n",
    "    'top_triggers': dict(trigger_counts.most_common(15)),\n",
    "    'symptom_durations': dict(duration_counts),\n",
    "    'top_symptoms': dict(symptom_counts.most_common(20)),\n",
    "    'cognitive_distortions': dict(distortion_counts),\n",
    "    'support_levels': dict(support_counts),\n",
    "    'therapy_goals': dict(goal_counts)\n",
    "}\n",
    "\n",
    "with open(f\"{output_dir}/analysis/meta_analysis_statistics.json\", 'w') as f:\n",
    "    json.dump(meta_analysis, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Meta-analysis saved to: {output_dir}/analysis/meta_analysis_statistics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Meta-Analysis: Cognitive Actions (If Probes Available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cognitive actions detected across all sessions\n",
    "print(f\"{'='*80}\")\n",
    "print(\"META-ANALYSIS: COGNITIVE ACTIONS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "therapist_actions = Counter()\n",
    "client_actions = Counter()\n",
    "sessions_with_probes = 0\n",
    "\n",
    "for session in all_sessions:\n",
    "    conversation = session['conversation']\n",
    "    \n",
    "    for i, turn in enumerate(conversation):\n",
    "        if 'predictions' in turn:\n",
    "            sessions_with_probes += 1\n",
    "            # Turn 0 is initial opening, odd turns are therapist, even are client\n",
    "            is_therapist = (i % 2 == 1)\n",
    "            \n",
    "            predictions = turn['predictions']\n",
    "            for pred in predictions:\n",
    "                if pred.get('is_active', False):\n",
    "                    action = pred['action']\n",
    "                    count_weight = pred.get('count', 1)\n",
    "                    \n",
    "                    if is_therapist:\n",
    "                        therapist_actions[action] += count_weight\n",
    "                    else:\n",
    "                        client_actions[action] += count_weight\n",
    "\n",
    "if therapist_actions or client_actions:\n",
    "    print(f\"‚úÖ Found cognitive action data in {sessions_with_probes} sessions\\n\")\n",
    "    \n",
    "    print(\"1Ô∏è‚É£ TOP THERAPIST COGNITIVE ACTIONS\")\n",
    "    print(\"-\" * 80)\n",
    "    for action, count in therapist_actions.most_common(20):\n",
    "        bar = \"‚ñà\" * (count // 10)\n",
    "        print(f\"  {action:35s} {count:4d} {bar}\")\n",
    "    \n",
    "    print(f\"\\n2Ô∏è‚É£ TOP CLIENT COGNITIVE ACTIONS\")\n",
    "    print(\"-\" * 80)\n",
    "    for action, count in client_actions.most_common(20):\n",
    "        bar = \"‚ñà\" * (count // 10)\n",
    "        print(f\"  {action:35s} {count:4d} {bar}\")\n",
    "    \n",
    "    # Unique to each role\n",
    "    therapist_only = set(therapist_actions.keys()) - set(client_actions.keys())\n",
    "    client_only = set(client_actions.keys()) - set(therapist_actions.keys())\n",
    "    \n",
    "    if therapist_only:\n",
    "        print(f\"\\n3Ô∏è‚É£ COGNITIVE ACTIONS UNIQUE TO THERAPIST\")\n",
    "        print(\"-\" * 80)\n",
    "        for action in sorted(therapist_only):\n",
    "            print(f\"  ‚Ä¢ {action}\")\n",
    "    \n",
    "    if client_only:\n",
    "        print(f\"\\n4Ô∏è‚É£ COGNITIVE ACTIONS UNIQUE TO CLIENT\")\n",
    "        print(\"-\" * 80)\n",
    "        for action in sorted(client_only):\n",
    "            print(f\"  ‚Ä¢ {action}\")\n",
    "    \n",
    "    # Save cognitive action analysis\n",
    "    cognitive_analysis = {\n",
    "        'sessions_analyzed': sessions_with_probes,\n",
    "        'therapist_top_actions': dict(therapist_actions.most_common(30)),\n",
    "        'client_top_actions': dict(client_actions.most_common(30)),\n",
    "        'therapist_unique': list(therapist_only),\n",
    "        'client_unique': list(client_only)\n",
    "    }\n",
    "    \n",
    "    with open(f\"{output_dir}/analysis/cognitive_action_analysis.json\", 'w') as f:\n",
    "        json.dump(cognitive_analysis, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Cognitive action analysis saved to: {output_dir}/analysis/cognitive_action_analysis.json\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No cognitive action data found. Probes may not be loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ Visualize Meta-Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (16, 12)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 14))\n",
    "\n",
    "# 1. Presenting issues\n",
    "ax1 = axes[0, 0]\n",
    "issue_data = meta_df['primary_issue'].value_counts()\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#95E1D3']\n",
    "ax1.pie(issue_data.values, labels=issue_data.index, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "ax1.set_title('Distribution of Presenting Issues', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Top triggers\n",
    "ax2 = axes[0, 1]\n",
    "trigger_data = Counter(meta_df['trigger_context']).most_common(8)\n",
    "triggers, counts = zip(*trigger_data)\n",
    "ax2.barh(range(len(triggers)), counts, color='steelblue', alpha=0.7)\n",
    "ax2.set_yticks(range(len(triggers)))\n",
    "ax2.set_yticklabels([t[:40] + '...' if len(t) > 40 else t for t in triggers], fontsize=9)\n",
    "ax2.set_xlabel('Frequency', fontsize=10)\n",
    "ax2.set_title('Top 8 Trigger Contexts', fontsize=14, fontweight='bold')\n",
    "ax2.invert_yaxis()\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Symptom durations\n",
    "ax3 = axes[1, 0]\n",
    "duration_data = Counter(meta_df['symptom_duration']).most_common()\n",
    "durations, d_counts = zip(*duration_data)\n",
    "ax3.bar(range(len(durations)), d_counts, color='coral', alpha=0.7)\n",
    "ax3.set_xticks(range(len(durations)))\n",
    "ax3.set_xticklabels(durations, rotation=45, ha='right', fontsize=9)\n",
    "ax3.set_ylabel('Frequency', fontsize=10)\n",
    "ax3.set_title('Symptom Duration Distribution', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Top symptoms\n",
    "ax4 = axes[1, 1]\n",
    "all_symptoms = []\n",
    "for symp_list in meta_df['primary_symptoms']:\n",
    "    all_symptoms.extend(symp_list)\n",
    "symptom_data = Counter(all_symptoms).most_common(10)\n",
    "symptoms, s_counts = zip(*symptom_data)\n",
    "ax4.barh(range(len(symptoms)), s_counts, color='lightgreen', alpha=0.7)\n",
    "ax4.set_yticks(range(len(symptoms)))\n",
    "ax4.set_yticklabels([s[:40] + '...' if len(s) > 40 else s for s in symptoms], fontsize=9)\n",
    "ax4.set_xlabel('Frequency', fontsize=10)\n",
    "ax4.set_title('Top 10 Primary Symptoms', fontsize=14, fontweight='bold')\n",
    "ax4.invert_yaxis()\n",
    "ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 5. Cognitive distortions\n",
    "ax5 = axes[2, 0]\n",
    "distortion_data = Counter(meta_df['cognitive_distortion']).most_common(8)\n",
    "distortions, dist_counts = zip(*distortion_data)\n",
    "ax5.bar(range(len(distortions)), dist_counts, color='orange', alpha=0.7)\n",
    "ax5.set_xticks(range(len(distortions)))\n",
    "ax5.set_xticklabels([d[:20] + '...' if len(d) > 20 else d for d in distortions], \n",
    "                     rotation=45, ha='right', fontsize=9)\n",
    "ax5.set_ylabel('Frequency', fontsize=10)\n",
    "ax5.set_title('Cognitive Distortions Represented', fontsize=14, fontweight='bold')\n",
    "ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 6. Support levels\n",
    "ax6 = axes[2, 1]\n",
    "support_data = Counter(meta_df['support_level']).most_common()\n",
    "supports, sup_counts = zip(*support_data)\n",
    "ax6.barh(range(len(supports)), sup_counts, color='purple', alpha=0.7)\n",
    "ax6.set_yticks(range(len(supports)))\n",
    "ax6.set_yticklabels([s[:40] + '...' if len(s) > 40 else s for s in supports], fontsize=9)\n",
    "ax6.set_xlabel('Frequency', fontsize=10)\n",
    "ax6.set_title('Support System Levels', fontsize=14, fontweight='bold')\n",
    "ax6.invert_yaxis()\n",
    "ax6.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/analysis/meta_analysis_visualization.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Visualization saved to: {output_dir}/analysis/meta_analysis_visualization.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£4Ô∏è‚É£ Visualize Cognitive Actions (If Available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if therapist_actions and client_actions:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Therapist actions\n",
    "    ax1 = axes[0]\n",
    "    top_therapist = dict(therapist_actions.most_common(15))\n",
    "    actions_t = list(top_therapist.keys())\n",
    "    counts_t = list(top_therapist.values())\n",
    "    ax1.barh(range(len(actions_t)), counts_t, color='steelblue', alpha=0.8)\n",
    "    ax1.set_yticks(range(len(actions_t)))\n",
    "    ax1.set_yticklabels(actions_t, fontsize=9)\n",
    "    ax1.set_xlabel('Frequency Across All Sessions', fontsize=11)\n",
    "    ax1.set_title('Top 15 Therapist Cognitive Actions', fontsize=14, fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Client actions\n",
    "    ax2 = axes[1]\n",
    "    top_client = dict(client_actions.most_common(15))\n",
    "    actions_c = list(top_client.keys())\n",
    "    counts_c = list(top_client.values())\n",
    "    ax2.barh(range(len(actions_c)), counts_c, color='coral', alpha=0.8)\n",
    "    ax2.set_yticks(range(len(actions_c)))\n",
    "    ax2.set_yticklabels(actions_c, fontsize=9)\n",
    "    ax2.set_xlabel('Frequency Across All Sessions', fontsize=11)\n",
    "    ax2.set_title('Top 15 Client Cognitive Actions', fontsize=14, fontweight='bold')\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/analysis/cognitive_actions_comparison.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Cognitive actions visualization saved to: {output_dir}/analysis/cognitive_actions_comparison.png\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No cognitive action data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£5Ô∏è‚É£ Export Dataset for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV export for easy analysis\n",
    "export_data = []\n",
    "\n",
    "for session in all_sessions:\n",
    "    meta = session['metadata']\n",
    "    conv = session['conversation']\n",
    "    \n",
    "    # Count turns by role\n",
    "    therapist_turns = sum(1 for i, turn in enumerate(conv) if i % 2 == 1 and i > 0)\n",
    "    client_turns = sum(1 for i, turn in enumerate(conv) if i % 2 == 0 or i == 0)\n",
    "    \n",
    "    # Extract text lengths\n",
    "    total_words = sum(len(turn.get('content', '').split()) for turn in conv)\n",
    "    \n",
    "    export_data.append({\n",
    "        'session_id': meta['session_id'],\n",
    "        'primary_issue': meta['primary_issue'],\n",
    "        'num_primary_symptoms': len(meta['primary_symptoms']),\n",
    "        'num_secondary_symptoms': len(meta['secondary_symptoms']),\n",
    "        'trigger_context': meta['trigger_context'],\n",
    "        'symptom_duration': meta['symptom_duration'],\n",
    "        'emotional_presentation': meta['emotional_presentation'],\n",
    "        'cognitive_distortion': meta['cognitive_distortion'],\n",
    "        'support_level': meta['support_level'],\n",
    "        'coping_attempts': meta['coping_attempts'],\n",
    "        'therapy_goal': meta['therapy_goal'],\n",
    "        'total_turns': len(conv),\n",
    "        'therapist_turns': therapist_turns,\n",
    "        'client_turns': client_turns,\n",
    "        'total_words': total_words\n",
    "    })\n",
    "\n",
    "export_df = pd.DataFrame(export_data)\n",
    "csv_file = f\"{output_dir}/analysis/sessions_dataset.csv\"\n",
    "export_df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset exported to CSV: {csv_file}\")\n",
    "print(f\"\\nDataset shape: {export_df.shape}\")\n",
    "print(f\"\\nSample rows:\")\n",
    "print(export_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£6Ô∏è‚É£ Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ THERAPEUTIC CONVERSATION SIMULATION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Generated Data:\")\n",
    "print(f\"   ‚Ä¢ {len(all_sessions)} complete therapy sessions\")\n",
    "print(f\"   ‚Ä¢ {sum(len(s['conversation']) for s in all_sessions)} total conversation turns\")\n",
    "print(f\"   ‚Ä¢ Depression sessions: {sum(1 for s in all_sessions if s['metadata']['primary_issue'] == 'depression')}\")\n",
    "print(f\"   ‚Ä¢ Anxiety sessions: {sum(1 for s in all_sessions if s['metadata']['primary_issue'] == 'anxiety')}\")\n",
    "print(f\"   ‚Ä¢ Combined sessions: {sum(1 for s in all_sessions if s['metadata']['primary_issue'] == 'both')}\")\n",
    "\n",
    "print(f\"\\nüìÅ Output Files:\")\n",
    "print(f\"   ‚Ä¢ Individual sessions: {output_dir}/conversations/\")\n",
    "print(f\"   ‚Ä¢ Complete dataset: {output_dir}/all_sessions_{NUM_SESSIONS}.json\")\n",
    "print(f\"   ‚Ä¢ Meta-analysis stats: {output_dir}/analysis/meta_analysis_statistics.json\")\n",
    "print(f\"   ‚Ä¢ Cognitive actions: {output_dir}/analysis/cognitive_action_analysis.json\")\n",
    "print(f\"   ‚Ä¢ CSV export: {output_dir}/analysis/sessions_dataset.csv\")\n",
    "print(f\"   ‚Ä¢ Visualizations: {output_dir}/analysis/*.png\")\n",
    "\n",
    "print(f\"\\nüé≤ Variation Achieved:\")\n",
    "print(f\"   ‚Ä¢ {len(meta_df['trigger_context'].unique())} unique trigger contexts\")\n",
    "print(f\"   ‚Ä¢ {len(meta_df['symptom_duration'].unique())} different symptom durations\")\n",
    "print(f\"   ‚Ä¢ {len(meta_df['cognitive_distortion'].unique())} cognitive distortions\")\n",
    "print(f\"   ‚Ä¢ {len(meta_df['emotional_presentation'].unique())} emotional presentations\")\n",
    "\n",
    "print(f\"\\nüîç Next Steps:\")\n",
    "print(f\"   1. Download all files from Google Drive: {output_dir}\")\n",
    "print(f\"   2. Use CSV for statistical analysis in R, Python, or Excel\")\n",
    "print(f\"   3. Analyze conversation patterns and therapeutic techniques\")\n",
    "print(f\"   4. Train models on the conversation data\")\n",
    "print(f\"   5. Compare cognitive actions across depression vs anxiety\")\n",
    "print(f\"   6. Identify effective therapeutic interventions\")\n",
    "\n",
    "print(f\"\\nüí° Research Applications:\")\n",
    "print(f\"   ‚Ä¢ Training conversational AI for mental health support\")\n",
    "print(f\"   ‚Ä¢ Studying therapeutic dialogue patterns\")\n",
    "print(f\"   ‚Ä¢ Identifying cognitive action signatures of depression/anxiety\")\n",
    "print(f\"   ‚Ä¢ Testing intervention effectiveness\")\n",
    "print(f\"   ‚Ä¢ Developing assessment tools\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All data saved to Google Drive!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
